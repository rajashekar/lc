[
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "context_length": 0,
    "created": 0,
    "display_name": "Cartesia Sonic",
    "id": "cartesia/sonic",
    "link": "https://www.cartesia.ai",
    "object": "model",
    "organization": "Together",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 65,
      "output": 0
    },
    "running": false,
    "type": "audio"
  },
  {
    "config": {
      "bos_token": "<s>",
      "chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\\n' + system_message + '\\n<</SYS>>\\n\\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' or message['role'] == 'tool' %}{{ bos_token + '[INST] ' + content + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>\\n' + content + '\\n<</SYS>>\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content + ' ' + eos_token }}{% endif %}{% endfor %}",
      "eos_token": "</s>",
      "stop": [
        "</s>"
      ]
    },
    "context_length": 32768,
    "created": 1716406261,
    "display_name": "Mistral (7B) Instruct v0.3",
    "id": "mistralai/Mistral-7B-Instruct-v0.3",
    "license": "apache-2.0",
    "link": "https://huggingface.co/api/models/mistralai/Mistral-7B-Instruct-v0.3",
    "object": "model",
    "organization": "mistralai",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.2,
      "output": 0.2
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "context_length": 0,
    "created": 0,
    "display_name": "Cartesia Sonic 2",
    "id": "cartesia/sonic-2",
    "link": "https://www.cartesia.ai",
    "object": "model",
    "organization": "Together",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 65,
      "output": 0
    },
    "running": false,
    "type": "audio"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "context_length": 32768,
    "created": 1733856970,
    "display_name": "Together AI MoA-1",
    "id": "togethercomputer/MoA-1",
    "link": "https://github.com/togethercomputer/MoA",
    "object": "model",
    "organization": "Together AI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": "{% if messages.length % 2 == 0 %}{% set final_role = 'Agent' %}{% else %}{% set final_role = 'User' %}{% endif %}<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\nTask: Check if there is unsafe content in '{{ final_role }}' messages in conversations according our safety policy with the below categories.\n\n<BEGIN UNSAFE CONTENT CATEGORIES>\nS1: Violent Crimes.\nS2: Non-Violent Crimes.\nS3: Sex Crimes.\nS4: Child Exploitation.\nS5: Defamation.\nS6: Specialized Advice.\nS7: Privacy.\nS8: Intellectual Property.\nS9: Indiscriminate Weapons.\nS10: Hate.\nS11: Self-Harm.\nS12: Sexual Content.\nS13: Elections.\nS14: Code Interpreter Abuse.\n<END UNSAFE CONTENT CATEGORIES>\n\n<BEGIN CONVERSATION>\n\n{% for message in messages %}{% if message['role'] == 'user' and loop.index0 % 2 == 0 %}User: {{ message['content'].trim() }}{% elif message['role'] == 'assistant' and loop.index0 % 2 != 0 %}Agent: {{ message['content'].trim() }}{% endif %}{% if loop.last %}{% set role = message['role'] %}{% endif %}{{ '\n\n' }}{% endfor %}<END CONVERSATION>\n\nProvide your safety assessment for {{ role }} in the above conversation:\n - First line must read 'safe' or 'unsafe'.\n - If unsafe, a second line must include a comma-separated list of violated categories.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
      "eos_token": null,
      "stop": []
    },
    "context_length": 8192,
    "created": 1713429380,
    "display_name": "Meta Llama Guard 3 8B",
    "id": "meta-llama/Meta-Llama-Guard-3-8B",
    "license": "llama",
    "link": null,
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.2,
      "output": 0.2
    },
    "running": false,
    "type": "moderation"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "context_length": 32768,
    "created": 1699120644,
    "display_name": "M2-BERT-Retrieval-32k",
    "id": "togethercomputer/m2-bert-80M-32k-retrieval",
    "license": "apache-2.0",
    "link": "https://huggingface.co/togethercomputer/m2-bert-80M-32k-retrieval",
    "object": "model",
    "organization": "Together",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.008,
      "output": 0.008
    },
    "running": false,
    "type": "embedding"
  },
  {
    "config": {
      "bos_token": "<|endoftext|>",
      "chat_template": "{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- messages[0]['content'] }}\n    {%- else %}\n        {{- 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.' }}\n    {%- endif %}\n    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n    {%- else %}\n        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {{- '<|im_start|>' + message.role }}\n        {%- if message.content %}\n            {{- '\\n' + message.content }}\n        {%- endif %}\n        {%- for tool_call in message.tool_calls %}\n            {%- if tool_call.function is defined %}\n                {%- set tool_call = tool_call.function %}\n            {%- endif %}\n            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n            {{- tool_call.name }}\n            {{- '\", \"arguments\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- '}\\n</tool_call>' }}\n        {%- endfor %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n' }}\n{%- endif %}\n",
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>"
      ]
    },
    "context_length": 32768,
    "created": 1728671048,
    "display_name": "Qwen2.5 7B Instruct Turbo",
    "id": "Qwen/Qwen2.5-7B-Instruct-Turbo",
    "license": "Qwen",
    "link": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
    "object": "model",
    "organization": "Qwen",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.3,
      "output": 0.3
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "created": 0,
    "display_name": "FLUX.1 [pro]",
    "id": "black-forest-labs/FLUX.1-pro",
    "link": "https://huggingface.co/black-forest-labs/FLUX.1-schnell",
    "object": "model",
    "organization": "Black Forest Labs",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "image"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "created": 0,
    "display_name": "FLUX1.1 [pro]",
    "id": "black-forest-labs/FLUX.1.1-pro",
    "link": "https://huggingface.co/black-forest-labs/FLUX.1-schnell",
    "object": "model",
    "organization": "Black Forest Labs",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "image"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "created": 1748454089,
    "display_name": "Whisper large-v3",
    "id": "openai/whisper-large-v3",
    "license": "apache2",
    "link": "https://huggingface.co/openai/whisper-large-v3",
    "object": "model",
    "organization": "OpenAI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.27,
      "output": 0.85
    },
    "running": false,
    "type": "transcribe"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n\n' }}",
      "eos_token": "<|end_of_text|>",
      "stop": [
        "<|eot_id|>"
      ]
    },
    "context_length": 8192,
    "created": 1713420479,
    "display_name": "Meta Llama 3 8B Instruct Reference",
    "id": "meta-llama/Llama-3-8b-chat-hf",
    "license": "Llama-3 (Other)",
    "link": "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.2,
      "output": 0.2
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": null,
      "eos_token": "<|eot_id|>",
      "stop": [
        "<|eot_id|>",
        "<|eom_id|>"
      ]
    },
    "context_length": 130815,
    "created": 1721698359,
    "display_name": "Meta Llama 3.1 405B Instruct Turbo",
    "id": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
    "license": "llama",
    "link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 3.5,
      "output": 3.5
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "context_length": 32768,
    "created": 0,
    "display_name": "Together AI MoA-1-Turbo",
    "id": "togethercomputer/MoA-1-Turbo",
    "license": null,
    "link": "https://github.com/togethercomputer/MoA",
    "object": "model",
    "organization": "Together AI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "created": 1732148338,
    "display_name": "FLUX.1 Redux [dev]",
    "id": "black-forest-labs/FLUX.1-redux",
    "link": "https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev",
    "object": "model",
    "organization": "Black Forest Labs",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "image"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": null,
      "eos_token": "<|end_of_text|>",
      "stop": [
        "<|end_of_text|>"
      ]
    },
    "context_length": 12000,
    "created": 1751997365,
    "display_name": "Meta Llama 3.1 405B Fp8",
    "id": "eddiehou/meta-llama/Llama-3.1-405B",
    "license": "llama3.1",
    "link": "https://huggingface.co/api/models/togethercomputer/Meta-Llama-3.1-405B-FP8",
    "object": "model",
    "organization": "Togethercomputer",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<s>",
      "chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\\n' + system_message + '\\n<</SYS>>\\n\\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' or message['role'] == 'tool' %}{{ bos_token + '[INST] ' + content + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>\\n' + content + '\\n<</SYS>>\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content + ' ' + eos_token }}{% endif %}{% endfor %}",
      "eos_token": "</s>",
      "stop": [
        "[/INST]",
        "</s>"
      ]
    },
    "context_length": 32768,
    "created": 1702325373,
    "display_name": "Mistral (7B) Instruct v0.2",
    "id": "mistralai/Mistral-7B-Instruct-v0.2",
    "license": "apache-2.0",
    "object": "model",
    "organization": "mistralai",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.2,
      "output": 0.2
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "created": 1736906515,
    "display_name": "FLUX.1 [dev] LoRA",
    "id": "black-forest-labs/FLUX.1-dev-lora",
    "link": "https://huggingface.co/black-forest-labs/FLUX.1-dev",
    "object": "model",
    "organization": "Black Forest Labs",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "image"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = \"26 Jul 2024\" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0]['role'] == 'system' %}\n    {%- set system_message = messages[0]['content']|trim %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = \"\" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- \"Environment: ipython\\n\" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n{%- endif %}\n{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- \"<|eot_id|>\" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0]['content']|trim %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n{%- endif %}\n    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n    {{- first_user_message + \"<|eot_id|>\"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n    {%- elif 'tool_calls' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + '=\"' + arg_val + '\"' }}\n                {%- if not loop.last %}\n                    {{- \", \" }}\n                {%- endif %}\n                {%- endfor %}\n            {{- \")\" }}\n        {%- else  %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n            {{- '\"parameters\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- \"}\" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we're in ipython mode #}\n            {{- \"<|eom_id|>\" }}\n        {%- else %}\n            {{- \"<|eot_id|>\" }}\n        {%- endif %}\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- \"<|eot_id|>\" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n{%- endif %}\n",
      "eos_token": "<|eot_id|>",
      "stop": [
        "<|eot_id|>",
        "<|eom_id|>"
      ]
    },
    "context_length": 131072,
    "created": 1733967427,
    "display_name": "Meta Llama 3.3 70B Instruct Turbo Free",
    "id": "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
    "license": "Llama-3.3 (Other)",
    "link": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = \"26 Jul 2024\" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0]['role'] == 'system' %}\n    {%- set system_message = messages[0]['content']|trim %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = \"\" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- \"Environment: ipython\\n\" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n{%- endif %}\n{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- \"<|eot_id|>\" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0]['content']|trim %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n{%- endif %}\n    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n    {{- first_user_message + \"<|eot_id|>\"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n    {%- elif 'tool_calls' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + '=\"' + arg_val + '\"' }}\n                {%- if not loop.last %}\n                    {{- \", \" }}\n                {%- endif %}\n                {%- endfor %}\n            {{- \")\" }}\n        {%- else  %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n            {{- '\"parameters\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- \"}\" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we're in ipython mode #}\n            {{- \"<|eom_id|>\" }}\n        {%- else %}\n            {{- \"<|eot_id|>\" }}\n        {%- endif %}\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- \"<|eot_id|>\" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n{%- endif %}\n",
      "eos_token": "<|eot_id|>",
      "stop": [
        "<|eot_id|>",
        "<|eom_id|>"
      ]
    },
    "context_length": 131072,
    "created": 1741298134,
    "display_name": "Meta Llama 3.1 8B Instruct Turbo",
    "id": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
    "license": "Llama-3.1 (Other)",
    "link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.18000000000000002,
      "output": 0.18000000000000002
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{% for message in messages %}\n{% if loop.index0 == 0 %}{{ bos_token }}{% endif %}\n{{ '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n' }}\n{% if message['content'] is string %}\n{{ message['content'] }}\n{% else %}\n{% for content in message['content'] | sort(attribute=\"type\") %}\n{% if content['type'] == 'image' %}\n{{ '<|image|>' }}\n{% elif content['type'] == 'text' %}\n{{ content['text'] }}\n{% endif %}\n{% endfor %}\n{% endif %}\n{{ '<|eot_id|>' }}\n{% endfor %}\n{% if add_generation_prompt %}\n{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n{% endif %}",
      "eos_token": "<|eot_id|>",
      "stop": [
        "<|eot_id|>",
        "<|eom_id|>"
      ]
    },
    "context_length": 131072,
    "created": 1727218691,
    "display_name": "Meta Llama 3.2 11B Vision Instruct Turbo",
    "id": "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo",
    "license": "llama",
    "link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.18000000000000002,
      "output": 0.18000000000000002
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n\n' }}",
      "eos_token": "<|end_of_text|>",
      "stop": [
        "<|eot_id|>"
      ]
    },
    "context_length": 8192,
    "created": 0,
    "display_name": "Meta Llama 3 70B Instruct Turbo",
    "id": "meta-llama/Meta-Llama-3-70B-Instruct-Turbo",
    "license": "Llama-3 (Other)",
    "link": "https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.88,
      "output": 0.88
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = \"26 Jul 2024\" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0]['role'] == 'system' %}\n    {%- set system_message = messages[0]['content']|trim %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = \"\" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- \"Environment: ipython\\n\" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n{%- endif %}\n{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- \"<|eot_id|>\" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0]['content']|trim %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n{%- endif %}\n    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n    {{- first_user_message + \"<|eot_id|>\"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n    {%- elif 'tool_calls' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + '=\"' + arg_val + '\"' }}\n                {%- if not loop.last %}\n                    {{- \", \" }}\n                {%- endif %}\n                {%- endfor %}\n            {{- \")\" }}\n        {%- else  %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n            {{- '\"parameters\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- \"}\" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we're in ipython mode #}\n            {{- \"<|eom_id|>\" }}\n        {%- else %}\n            {{- \"<|eot_id|>\" }}\n        {%- endif %}\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- \"<|eot_id|>\" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n{%- endif %}\n",
      "eos_token": "<|eot_id|>",
      "stop": [
        "<|eot_id|>",
        "<|eom_id|>"
      ]
    },
    "context_length": 131072,
    "created": 1733466629,
    "display_name": "Meta Llama 3.3 70B Instruct Turbo",
    "id": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
    "license": "Llama-3.3 (Other)",
    "link": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.88,
      "output": 0.88
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<｜begin▁of▁sentence｜>",
      "chat_template": "{%- for message in messages -%}{%- if message.role == 'system' -%}{{- message.content -}}{%- endif -%}{%- if message.role == 'user' -%}{{- message.content -}}{%- endif -%}{%- if message.role == 'assistant' -%}{{- message.content -}}{%- endif -%}{%- if message.role == 'tool' -%}{{- message.content -}}{%- endif -%}{%- endfor -%}",
      "eos_token": "<｜end▁of▁sentence｜>",
      "max_output_length": 12288,
      "stop": [
        "<｜end▁of▁sentence｜>"
      ]
    },
    "context_length": 163840,
    "created": 1737396322,
    "display_name": "DeepSeek R1-0528",
    "id": "deepseek-ai/DeepSeek-R1",
    "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1",
    "object": "model",
    "organization": "DeepSeek",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 3,
      "output": 7
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": "{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n{% endif %}<|im_start|>{{ message['role'] }}\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\n{% else %}{% for content in message['content'] %}{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}{% set image_count.value = image_count.value + 1 %}{% if add_vision_id %}Picture {{ image_count.value }}: {% endif %}<|vision_start|><|image_pad|><|vision_end|>{% elif content['type'] == 'video' or 'video' in content %}{% set video_count.value = video_count.value + 1 %}{% if add_vision_id %}Video {{ video_count.value }}: {% endif %}<|vision_start|><|video_pad|><|vision_end|>{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\n{% endif %}",
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>",
        "<|endoftext|>"
      ]
    },
    "context_length": 32768,
    "created": 1742408085,
    "display_name": "Qwen2.5-VL (72B) Instruct",
    "id": "Qwen/Qwen2.5-VL-72B-Instruct",
    "license": "tongyi-qianwen",
    "link": "https://huggingface.co/api/models/Qwen/Qwen2.5-VL-72B-Instruct",
    "object": "model",
    "organization": "Qwen",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 1.95,
      "output": 8
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "created": 0,
    "display_name": "FLUX.1 Schnell",
    "id": "black-forest-labs/FLUX.1-schnell",
    "link": "https://huggingface.co/black-forest-labs/FLUX.1-schnell",
    "object": "model",
    "organization": "Black Forest Labs",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "image"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{{ bos_token }}{%- set loop_messages = messages %}\n{%- if loop_messages[0]['role'] != 'system' %}\n<|im_start|>system\nYou are a helpful assistant named AFM-4.5B-Preview, trained by Arcee AI.<|im_end|>\n{%- endif %}\n{%- for message in loop_messages %}\n{%- set content = '<|im_start|>' + message['role'] + '\\n'+ message['content'] | trim %}\n{%- if loop.index0 == 0 %}\n{%- set content = content %}\n{%- endif %}\n{%- if not (loop.last and message['role'] == 'assistant') %}\n{%- set content = content + '<|im_end|>\\n' %}\n{%- endif %}\n{{- content }}\n{%- endfor %}\n{%- if messages[-1]['role'] != 'assistant' %}\n{{- '<|im_start|>assistant\\n' }}\n{%- endif %}",
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>"
      ]
    },
    "context_length": 65536,
    "created": 1750264042,
    "display_name": "AFM-4.5B-Preview",
    "id": "arcee-ai/AFM-4.5B-Preview",
    "link": "https://huggingface.co/api/models/togethercomputer/AFM-64k-distillmerge-pocketSFT-v0.0.3-2",
    "object": "model",
    "organization": "Arcee AI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "[BOS]",
      "chat_template": "{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\n' }}{% endif %}{{ '[|' + message['role'] + '|]' + message['content'] }}{% if message['role'] == 'user' %}{{ '\n' }}{% else %}{{ '[|endofturn|]\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '[|assistant|]' }}{% endif %}",
      "eos_token": "[|endofturn|]",
      "stop": [
        "[|endofturn|]"
      ]
    },
    "context_length": 32768,
    "created": 1743446196,
    "display_name": "EXAONE 3.5 32B Instruct",
    "id": "lgai/exaone-3-5-32b-instruct",
    "license": "other exaone",
    "link": "https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-32B-Instruct",
    "object": "model",
    "organization": "LG AI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n\n' }}",
      "eos_token": "<|end_of_text|>",
      "stop": [
        "<|eot_id|>"
      ]
    },
    "context_length": 8192,
    "created": 1713429236,
    "display_name": "Meta Llama 3 70B Instruct Reference",
    "id": "meta-llama/Llama-3-70b-chat-hf",
    "license": "Llama-3 (Other)",
    "link": "https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.88,
      "output": 0.88
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<s>",
      "chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\\n' + system_message + '\\n<</SYS>>\\n\\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' or message['role'] == 'tool' %}{{ bos_token + '[INST] ' + content + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>\\n' + content + '\\n<</SYS>>\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content + ' ' + eos_token }}{% endif %}{% endfor %}",
      "eos_token": "</s>",
      "stop": [
        "[/INST]",
        "</s>"
      ]
    },
    "context_length": 32768,
    "created": 1702342468,
    "display_name": "Mixtral-8x7B Instruct v0.1",
    "id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "license": "apache-2.0",
    "link": "https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1",
    "object": "model",
    "organization": "mistralai",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.6,
      "output": 0.6
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "created": 1732141533,
    "display_name": "FLUX.1 Depth [dev]",
    "id": "black-forest-labs/FLUX.1-depth",
    "link": "https://huggingface.co/black-forest-labs/FLUX.1-Depth-dev",
    "object": "model",
    "organization": "Black Forest Labs",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "image"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "created": 1750904593,
    "display_name": "FLUX.1 Kontext [dev]",
    "id": "black-forest-labs/FLUX.1-kontext-dev",
    "object": "model",
    "organization": "Black Forest Labs",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "image"
  },
  {
    "config": {
      "bos_token": "<bos>",
      "chat_template": "{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}",
      "eos_token": "<end_of_turn>",
      "stop": [
        "<eos>",
        "<end_of_turn>"
      ]
    },
    "context_length": 8192,
    "created": 1708648606,
    "display_name": "Gemma-2 Instruct (27B)",
    "id": "google/gemma-2-27b-it",
    "license": "gemma-terms-of-use",
    "link": "https://huggingface.co/google/gemma-2b-it",
    "object": "model",
    "organization": "Google",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.8,
      "output": 0.8
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "created": 1732138026,
    "display_name": "FLUX.1 [dev]",
    "id": "black-forest-labs/FLUX.1-dev",
    "link": "https://huggingface.co/black-forest-labs/FLUX.1-dev",
    "object": "model",
    "organization": "Black Forest Labs",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "image"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "eos_token": null,
      "stop": [
        "<|im_start|>",
        "<|im_end|>"
      ]
    },
    "context_length": 32768,
    "created": 1744167438,
    "display_name": "Qwen 2 Instruct (72B)",
    "id": "Qwen/Qwen2-72B-Instruct",
    "license": "tongyi-qianwen",
    "link": "https://huggingface.co/Qwen/Qwen2-72B-Instruct",
    "object": "model",
    "organization": "Qwen",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.9,
      "output": 0.9
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<s>",
      "chat_template": null,
      "eos_token": "</s>",
      "stop": [
        "</s>"
      ]
    },
    "context_length": 4096,
    "created": 1689720415,
    "display_name": "LLaMA-2 (70B)",
    "id": "meta-llama/Llama-2-70b-hf",
    "license": "llama2",
    "link": "https://huggingface.co/api/models/meta-llama/Llama-2-70b-hf",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.9,
      "output": 0.9
    },
    "running": false,
    "type": "language"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "created": 1732144835,
    "display_name": "FLUX.1 Canny [dev]",
    "id": "black-forest-labs/FLUX.1-canny",
    "link": "https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev",
    "object": "model",
    "organization": "Black Forest Labs",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "image"
  },
  {
    "config": {
      "bos_token": "<|endoftext|>",
      "chat_template": null,
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>"
      ]
    },
    "context_length": 40960,
    "created": 1747854468,
    "display_name": "Qwen3 235B A22B FP8 Throughput",
    "id": "Qwen/Qwen3-235B-A22B-fp8-tput",
    "license": "apache-2.0",
    "link": "https://huggingface.co/api/models/Qwen/Qwen3-235B-A22B",
    "object": "model",
    "organization": "Qwen",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.2,
      "output": 0.6
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n\nAfter carefully reading the query, document, and guidelines, I have determined that the relevance score is: ' }}{% endif %}",
      "eos_token": "<|eot_id|>",
      "stop": [
        "<|eot_id|>"
      ]
    },
    "context_length": 8192,
    "created": 1723745254,
    "display_name": "Salesforce Llama Rank V1 (8B)",
    "id": "Salesforce/Llama-Rank-V1",
    "license": "llama3",
    "object": "model",
    "organization": "salesforce",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.1,
      "output": 0.1
    },
    "running": false,
    "type": "rerank"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": "{%- if messages[0][\"role\"] == \"system\" %}{%- set system_message = messages[0][\"content\"] %}{%- set loop_messages = messages[1:] %}{%- else %}{%- set today = strftime_now(\"%Y-%m-%d\") %}{%- set system_message = \"You are Mistral Small 3, a Large Language Model (LLM) created by Mistral AI, a French startup headquartered in Paris.\\nYour knowledge base was last updated on 2023-10-01. The current date is \" + today + \".\\n\\nWhen you're not sure about some information, you say that you don't have the information and don't make up anything.\\nIf the user's question is not clear, ambiguous, or does not provide enough context for you to accurately answer the question, you do not try to answer it right away and you rather ask the user to clarify their request (e.g. \\\"What are some good restaurants around me?\\\" => \\\"Where are you?\\\" or \\\"When is the next flight to Tokyo\\\" => \\\"Where do you travel from?\\\")\" %}{%- set loop_messages = messages %}{%- endif %}{%- if not tools is defined %}{%- set tools = none %}{%- elif tools is not none %}{%- set parallel_tool_prompt = \"You are a helpful assistant that can call tools. If you call one or more tools, format them in a single JSON array or objects, where each object is a tool call, not as separate objects outside of an array or multiple arrays. Use the format [{\\\"name\\\": tool call name, \\\"arguments\\\": tool call arguments}, additional tool calls] if you call more than one tool. If you call tools, do not attempt to interpret them or otherwise provide a response until you receive a tool call result that you can interpret for the user.\" %}{%- if system_message is defined %}{%- set system_message = parallel_tool_prompt + \"\\n\\n\" + system_message %}{%- else %}{%- set system_message = parallel_tool_prompt %}{%- endif %}\n{%- endif %}{%- set user_messages = loop_messages | selectattr(\"role\", \"equalto\", \"user\") | list %}{%- for message in loop_messages | rejectattr(\"role\", \"equalto\", \"tool\") | rejectattr(\"role\", \"equalto\", \"tool_results\") | selectattr(\"tool_calls\", \"undefined\") %}{%- if (message[\"role\"] == \"user\") != (loop.index0 % 2 == 0) %}{{- raise_exception(\"After the optional system message, conversation roles must alternate user/assistant/user/assistant/...\") }}{%- endif %}{%- endfor %}{{- bos_token }}{%- for message in loop_messages %}{%- if message[\"role\"] == \"user\" %}{%- if tools is not none and (message == user_messages[user_messages.length-1]) %}{{- \"[AVAILABLE_TOOLS] [\" }}{%- for tool in tools %}{%- set tool = tool.function %}{{- '{\"type\": \"function\", \"function\": {' }}{%- for key, val in tool.items() if key != \"return\" %}{%- if val is string %}{{- '\"' + key + '\": \"' + val + '\"' }}{%- else %}{{- '\"' + key + '\": ' + val|tojson }}{%- endif %}{%- if not loop.last %}{{- \", \" }}{%- endif %}{%- endfor %}{{- \"}}\" }}{%- if not loop.last %}{{- \", \" }}{%- else %}{{- \"]\" }}{%- endif %}{%- endfor %}{{- \"[/AVAILABLE_TOOLS]\" }}{%- endif %}{%- if loop.last and system_message is defined %}{{- \"[SYSTEM_PROMPT]\" + system_message + \"[/SYSTEM_PROMPT][INST]\" + message[\"content\"] + \"[/INST]\" }}{%- else %}{{- \"[INST]\" + message[\"content\"] + \"[/INST]\" }}{%- endif %}{%- elif message[\"role\"] == \"tool_calls\" or message.tool_calls is defined %}{%- if message.tool_calls is defined %}{%- set tool_calls = message.tool_calls %}{%- else %}{%- set tool_calls = message.content %}{%- endif %}{{- \"[TOOL_CALLS] [\" }}{%- for tool_call in tool_calls %}{%- set out = tool_call.function|tojson %}{{- out }}{%- if not tool_call.id is defined or tool_call.id|length < 9 %}{{- raise_exception(\"Tool call IDs should be alphanumeric strings with length >= 9! (1)\" + tool_call.id) }}{%- endif %}{{- ', \"id\": \"' + tool_call.id + '\"}' }}{%- if not loop.last %}{{- \", \" }}{%- else %}{{- \"]\" + eos_token }}{%- endif %}{%- endfor %}{%- elif message[\"role\"] == \"assistant\" %}{{- \" \" + message[\"content\"] + eos_token }}{%- elif message[\"role\"] == \"tool_results\" or message[\"role\"] == \"tool\" %}{%- if message.content is defined and message.content.content is defined %}{%- set content = message.content.content %}{%- else %}{%- set content = message.content %}{%- endif %}{{- '[TOOL_RESULTS] {\"content\": ' + content|string + \", \" }}{%- if not message.tool_call_id is defined or message.tool_call_id|length < 9 %}{{- raise_exception(\"Tool call IDs should be alphanumeric strings with length >= 9! (2)\" + message.tool_call_id) }}{%- endif %}{{- '\"call_id\": \"' + message.tool_call_id + '\"}[/TOOL_RESULTS]' }}{%- else %}{{- raise_exception(\"Only user and assistant roles are supported, with the exception of an initial optional system message!\") }}{%- endif %}\n{%- endfor %}",
      "eos_token": null,
      "stop": [
        "[/INST]",
        "</s>"
      ]
    },
    "context_length": 32768,
    "created": 1738246136,
    "display_name": "Mistral Small (24B) Instruct 25.01",
    "id": "mistralai/Mistral-Small-24B-Instruct-2501",
    "license": "apache-2.0",
    "link": "https://huggingface.co/mistralai/Mistral-Small-Instruct-2501",
    "object": "model",
    "organization": "mistralai",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.8,
      "output": 0.8
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": "{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n{% endif %}<|im_start|>{{ message['role'] }}\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\n{% else %}{% for content in message['content'] %}{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}{% set image_count.value = image_count.value + 1 %}{% if add_vision_id %}Picture {{ image_count.value }}: {% endif %}<|vision_start|><|image_pad|><|vision_end|>{% elif content['type'] == 'video' or 'video' in content %}{% set video_count.value = video_count.value + 1 %}{% if add_vision_id %}Video {{ video_count.value }}: {% endif %}<|vision_start|><|video_pad|><|vision_end|>{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\n{% endif %}",
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>",
        "<|endoftext|>"
      ]
    },
    "context_length": 32768,
    "created": 1736448718,
    "display_name": "Qwen2-VL (72B) Instruct",
    "id": "Qwen/Qwen2-VL-72B-Instruct",
    "license": "tongyi-qianwen",
    "link": "https://huggingface.co/Qwen/Qwen2-VL-72B-Instruct",
    "object": "model",
    "organization": "Qwen",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 1.2,
      "output": 1.2
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<｜begin▁of▁sentence｜>",
      "chat_template": "{% if not add_generation_prompt %}{% set add_generation_prompt = false %}{% endif %}{# Initialize variables since Nunjucks doesn't support namespace #}{% set is_first = false %}{% set is_tool = false %}{% set is_output_first = true %}{% set system_prompt = '' %}{# Get system prompt #}{% for message in messages %}{% if message.role == 'system' %}{% set system_prompt = message.content %}{% endif %}{% endfor %}{{bos_token}}{{system_prompt}}{% for message in messages %}{% if message.role == 'user' %}{% set is_tool = false %}<｜User｜>{{message.content}}{% endif %}{% if message.role == 'assistant' and not message.content %}{% set is_tool = false %}{% for tool in message.tool_calls %}{% if not is_first %}<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>{{tool.type}}<｜tool▁sep｜>{{tool.function.name}}```json{{tool.function.arguments}}```<｜tool▁call▁end｜>{% set is_first = true %}{% else %}<｜tool▁call▁begin｜>{{tool.type}}<｜tool▁sep｜>{{tool.function.name}}```json{{tool.function.arguments}}```<｜tool▁call▁end｜><｜tool▁calls▁end｜><｜end▁of▁sentence｜>{% endif %}{% endfor %}{% endif %}{% if message.role == 'assistant' and message.content %}{% if is_tool %}<｜tool▁outputs▁end｜>{{message.content}}<｜end▁of▁sentence｜>{% set is_tool = false %}{% else %}{% set content = message.content %}{% if '</think>' in content %}{% set parts = content | split('</think>') %}{% set content = parts[parts.length-1] %}{% endif %}<｜Assistant｜>{{content}}<｜end▁of▁sentence｜>{% endif %}{% endif %}{% if message.role == 'tool' %}{% set is_tool = true %}{% if is_output_first %}<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>{{message.content}}<｜tool▁output▁end｜>{% set is_output_first = false %}{% else %}<｜tool▁output▁begin｜>{{message.content}}<｜tool▁output▁end｜>{% endif %}{% endif %}{% endfor %}{% if is_tool %}<｜tool▁outputs▁end｜>{% endif %}{% if add_generation_prompt and not is_tool %}<｜Assistant｜>{% endif %}",
      "eos_token": "<｜end▁of▁sentence｜>",
      "stop": [
        "<｜end▁of▁sentence｜>"
      ]
    },
    "context_length": 131072,
    "created": 1738185844,
    "display_name": "DeepSeek R1 Distill Qwen 1.5B",
    "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "license": "mit",
    "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "object": "model",
    "organization": "DeepSeek",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.18000000000000002,
      "output": 0.18000000000000002
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{% for message in messages %}\n{% if loop.index0 == 0 %}{{ bos_token }}{% endif %}\n{{ '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n' }}\n{% if message['content'] is string %}\n{{ message['content'] }}\n{% else %}\n{% for content in message['content'] | sort(attribute=\"type\") %}\n{% if content['type'] == 'image' %}\n{{ '<|image|>' }}\n{% elif content['type'] == 'text' %}\n{{ content['text'] }}\n{% endif %}\n{% endfor %}\n{% endif %}\n{{ '<|eot_id|>' }}\n{% endfor %}\n{% if add_generation_prompt %}\n{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n{% endif %}",
      "eos_token": "<|eot_id|>",
      "stop": [
        "<|eot_id|>",
        "<|eom_id|>"
      ]
    },
    "context_length": 131072,
    "created": 1727236346,
    "display_name": "Meta Llama Vision Free",
    "id": "meta-llama/Llama-Vision-Free",
    "license": "llama",
    "link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<｜begin▁of▁sentence｜>",
      "chat_template": null,
      "eos_token": "<｜end▁of▁sentence｜>",
      "max_output_length": 32768,
      "stop": [
        "<｜end▁of▁sentence｜>"
      ]
    },
    "context_length": 163840,
    "created": 1746135809,
    "display_name": "R1 1776",
    "id": "perplexity-ai/r1-1776",
    "license": "mit",
    "link": "https://huggingface.co/api/models/perplexity-ai/r1-1776",
    "object": "model",
    "organization": "Perplexity AI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 3,
      "output": 7
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = \"26 Jul 2024\" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0]['role'] == 'system' %}\n    {%- set system_message = messages[0]['content']|trim %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = \"\" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n{{- system_message }}\n{%- if tools is not none %}\n    {{- \"\\n\" }}\n    {{- \"You are given a question and a set of possible functions. Based on the question, you will need to make one or more function/tool calls to achieve the purpose.\" }}\n    {{- \"If none of the function can be used, point it out. If the given question lacks the parameters required by the function, also point it out.\" }}\n    {{- \"You should only return the function call in tools call sections.\" }}\n    {{- \"If you decide to invoke any of the function(s), you MUST put it in the format of [Function(arguments1={{params_name1: params_value1,params_name2: params_value2, ...}},  name1=function_name1), Function(arguments2={{params}},  name2=function_name2) , ...]\"}}\n    {{- \"You SHOULD NOT include any other text in the response.\\nHere is a list of functions in JSON format that you can invoke.\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n{%- endif %}\n{{- \"<|eot_id|>\" }}\n\n\n{%- for message in messages %}\n    {%- if not (message.role == 'tool') %}\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n    {%- elif message.role == \"tool\" %}\n        {{- \"<|start_header_id|>tool<|end_header_id|>\\n\\n\" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- \"<|eot_id|>\" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n{%- endif %}",
      "eos_token": "<|eot_id|>",
      "stop": [
        "<|eot_id|>"
      ]
    },
    "context_length": 8192,
    "created": 1743036812,
    "display_name": "Typhoon 2 70B Instruct",
    "id": "scb10x/scb10x-llama3-1-typhoon2-70b-instruct",
    "license": "llama3.1",
    "link": "https://huggingface.co/api/models/scb10x/llama3.1-typhoon2-70b-instruct",
    "object": "model",
    "organization": "SCB10X",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.88,
      "output": 0.88
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{%- if messages|length % 2 == 0 -%}\n    {%- set role = 'Agent' -%}\n{%-  else -%}\n    {%-  set role = 'User' -%}\n{%-  endif -%}\n{%-  if categories is not defined -%}\n    {%-  \n        set categories = ({\n            \"S1\": \"Violent Crimes.\",\n            \"S2\": \"Non-Violent Crimes.\",\n            \"S3\": \"Sex Crimes.\",\n            \"S4\": \"Child Exploitation.\",\n            \"S5\": \"Defamation.\",\n            \"S6\": \"Specialized Advice.\",\n            \"S7\": \"Privacy.\",\n            \"S8\": \"Intellectual Property.\",\n            \"S9\": \"Indiscriminate Weapons.\",\n            \"S10\": \"Hate.\",\n            \"S11\": \"Self-Harm.\",\n            \"S12\": \"Sexual Content.\",\n            \"S13\": \"Elections.\",\n        })\n    -%}\n{%-  endif -%}\n\n{{- \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\n\" -}}\n{%- set ns = namespace(contains_image=false) -%}\n{%-  for message in messages -%}\n    {%- for content in message['content'] | selectattr('type', 'equalto', 'image') -%}\n        {%- set ns.contains_image = true -%}\n    {%- endfor -%}\n{%- endfor -%}\n{%- if ns.contains_image -%}\n{{- \"<|image|> \"-}}\n{%- endif -%}\n{{- \"Task: Check if there is unsafe content in '\" + role + \"' messages in conversations according our safety policy with the below categories.\\n\\n\" -}}\n{{- \"<BEGIN UNSAFE CONTENT CATEGORIES>\\n\"-}}\n\n{%-  for key in categories -%}\n    {%-  if key not in excluded_category_keys -%}\n        {{-key + \": \" + categories[key] + \"\\n\" -}}\n    {%-  endif -%}\n{%-  endfor -%}\n\n{{- \"<END UNSAFE CONTENT CATEGORIES>\\n\\n\"-}}\n{{- \"<BEGIN CONVERSATION>\\n\\n\"-}}\n{%-  for message in messages -%}\n    {%-  if (message['role'] == 'user') != (loop.index0 % 2 == 0) -%}\n        {{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...')-}}\n    {%-  endif -%}\n    {%-  set content = message['content'] -%}\n    {%-  if message['role'] == 'user' -%}\n        {%-  set role = 'User' -%}\n    {%-  elif message['role'] == 'assistant' -%}\n        {%-  set role = 'Agent' -%}\n    {%-  endif -%}\n    {%-  for content in message['content'] | selectattr('type', 'equalto', 'text') -%}\n{{- role + ': ' + content['text'] | trim + '\\n\\n'-}}\n    {%-  endfor -%}\n{%-  endfor -%}\n{{- \"<END CONVERSATION>\\n\\n\"-}}\n{{- \"Provide your safety assessment for ONLY THE LAST \" + role + \" message in the above conversation:\\n\"-}}\n{{- \" - First line must read 'safe' or 'unsafe'.\\n\"-}}\n{{- \" - If unsafe, a second line must include a comma-separated list of violated categories. <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"-}}",
      "eos_token": "<|eot_id|>",
      "stop": [
        "<|eot_id|>",
        "<|eom_id|>"
      ]
    },
    "context_length": 131072,
    "created": 1727242489,
    "display_name": "Meta Llama Guard 3 11B Vision Turbo",
    "id": "meta-llama/Llama-Guard-3-11B-Vision-Turbo",
    "license": "llama",
    "link": "https://huggingface.co/meta-llama/Llama-Guard-3-11B-Vision",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.18000000000000002,
      "output": 0.18000000000000002
    },
    "running": false,
    "type": "moderation"
  },
  {
    "config": {
      "bos_token": "<|endoftext|>",
      "chat_template": "{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- messages[0]['content'] }}\n    {%- else %}\n        {{- '' }}\n    {%- endif %}\n    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n  {%- endif %}\n{%- endif %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" and not message.tool_calls %}\n        {%- set content = message.content %}\n        {%- if not loop.last %}\n            {%- set content = message.content.split('</think>')[-1].lstrip('\\n') %}\n        {%- endif %}\n        {{- '<|im_start|>' + message.role + '\\n' + content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {%- set content = message.content %}\n        {%- if not loop.last %}\n            {%- set content = message.content.split('</think>')[-1].lstrip('\\n') %}\n        {%- endif %}\n        {{- '<|im_start|>' + message.role }}\n        {%- if message.content %}\n            {{- '\\n' + content }}\n        {%- endif %}\n        {%- for tool_call in message.tool_calls %}\n            {%- if tool_call.function is defined %}\n                {%- set tool_call = tool_call.function %}\n            {%- endif %}\n            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n            {{- tool_call.name }}\n            {{- '\", \"arguments\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- '}\\n</tool_call>' }}\n        {%- endfor %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n<think>\\n' }}\n{%- endif %}\n",
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>"
      ]
    },
    "context_length": 131072,
    "created": 1743527998,
    "display_name": "Arcee AI Maestro",
    "id": "arcee-ai/maestro-reasoning",
    "link": "https://huggingface.co/api/models/togethercomputer/arcee-ai-maestro-32b-01",
    "object": "model",
    "organization": "Arcee AI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.9,
      "output": 3.3
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{% else %}{{ eos_token }}{% endif %}",
      "eos_token": "<|end_of_text|>",
      "stop": [
        "<|end_of_text|>"
      ]
    },
    "context_length": 8192,
    "created": 1747174868,
    "display_name": "Refuel LLM V2 Small",
    "id": "togethercomputer/Refuel-Llm-V2-Small",
    "link": "https://huggingface.co/api/models/togethercomputer/refuel-llm-v2-small",
    "object": "model",
    "organization": "Refuel AI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.2,
      "output": 0.2
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|endoftext|>",
      "chat_template": "{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- messages[0]['content'] }}\n    {%- else %}\n        {{- 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.' }}\n    {%- endif %}\n    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n    {%- else %}\n        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {{- '<|im_start|>' + message.role }}\n        {%- if message.content %}\n            {{- '\\n' + message.content }}\n        {%- endif %}\n        {%- for tool_call in message.tool_calls %}\n            {%- if tool_call.function is defined %}\n                {%- set tool_call = tool_call.function %}\n            {%- endif %}\n            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n            {{- tool_call.name }}\n            {{- '\", \"arguments\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- '}\\n</tool_call>' }}\n        {%- endfor %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n' }}\n{%- endif %}\n",
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>"
      ]
    },
    "context_length": 16384,
    "created": 1731556615,
    "display_name": "Qwen 2.5 Coder 32B Instruct",
    "id": "Qwen/Qwen2.5-Coder-32B-Instruct",
    "license": "Qwen",
    "link": "https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct",
    "object": "model",
    "organization": "Qwen",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.8,
      "output": 0.8
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|endoftext|>",
      "chat_template": "{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- messages[0]['content'] }}\n    {%- else %}\n        {{- 'You are Coder Large, created by Arcee AI. You are a helpful coding assistant.' }}\n    {%- endif %}\n    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n    {%- else %}\n        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {{- '<|im_start|>' + message.role }}\n        {%- if message.content %}\n            {{- '\\n' + message.content }}\n        {%- endif %}\n        {%- for tool_call in message.tool_calls %}\n            {%- if tool_call.function is defined %}\n                {%- set tool_call = tool_call.function %}\n            {%- endif %}\n            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n            {{- tool_call.name }}\n            {{- '\", \"arguments\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- '}\\n</tool_call>' }}\n        {%- endfor %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n' }}\n{%- endif %}\n",
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>"
      ]
    },
    "context_length": 32768,
    "created": 1745522718,
    "display_name": "Arcee AI Coder-Large",
    "id": "arcee-ai/coder-large",
    "link": "https://huggingface.co/api/models/togethercomputer/arcee-ai-coder-large",
    "object": "model",
    "organization": "Arcee AI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.5,
      "output": 0.8
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": "{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- messages[0]['content'] }}\n    {%- else %}\n        {{- 'You are a helpful and harmless assistant. You are Qwen developed by Alibaba. You should think step-by-step.' }}\n    {%- endif %}\n    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n    {%- else %}\n        {{- '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {{- '<|im_start|>' + message.role }}\n        {%- if message.content %}\n            {{- '\\n' + message.content }}\n        {%- endif %}\n        {%- for tool_call in message.tool_calls %}\n            {%- if tool_call.function is defined %}\n                {%- set tool_call = tool_call.function %}\n            {%- endif %}\n            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n            {{- tool_call.name }}\n            {{- '\", \"arguments\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- '}\\n</tool_call>' }}\n        {%- endfor %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n' }}\n{%- endif %}\n",
      "eos_token": "<|im_end|>",
      "max_output_length": 32768,
      "stop": [
        "<|im_end|>",
        "<|endoftext|>"
      ]
    },
    "context_length": 131072,
    "created": 1741207789,
    "display_name": "Qwen QwQ-32B",
    "id": "Qwen/QwQ-32B",
    "license": "Qwen",
    "link": "https://huggingface.co/Qwen/QwQ-32B",
    "object": "model",
    "organization": "Qwen",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 1.2,
      "output": 1.2
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|endoftext|>",
      "chat_template": "{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- messages[0]['content'] }}\n    {%- else %}\n        {{- 'You are a helpful assistant.' }}\n    {%- endif %}\n    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n    {%- else %}\n        {{- '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {{- '<|im_start|>' + message.role }}\n        {%- if message.content %}\n            {{- '\\n' + message.content }}\n        {%- endif %}\n        {%- for tool_call in message.tool_calls %}\n            {%- if tool_call.function is defined %}\n                {%- set tool_call = tool_call.function %}\n            {%- endif %}\n            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n            {{- tool_call.name }}\n            {{- '\", \"arguments\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- '}\\n</tool_call>' }}\n        {%- endfor %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n' }}\n{%- endif %}\n",
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>"
      ]
    },
    "context_length": 131072,
    "created": 1743530644,
    "display_name": "Arcee AI Spotlight",
    "id": "arcee_ai/arcee-spotlight",
    "link": "https://huggingface.co/api/models/togethercomputer/arcee-ai-spotlight-export",
    "object": "model",
    "organization": "Arcee AI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.18000000000000002,
      "output": 0.18000000000000002
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<s>",
      "chat_template": "{%- set today = strftime_now(\"%Y-%m-%d\") %}\n{%- set default_system_message = \"You are Arcee Blitz, a Large Language Model (LLM) created by Arcee AI.\\nYour knowledge base was last updated on 2024-10-01. The current date is \" + today + \".\\n\\nWhen you're not sure about some information, you say that you don't have the information and don't make up anything.\\nIf the user's question is not clear, ambiguous, or does not provide enough context for you to accurately answer the question, you do not try to answer it right away and you rather ask the user to clarify their request (e.g. \\\"What are some good restaurants around me?\\\" => \\\"Where are you?\\\" or \\\"When is the next flight to Tokyo\\\" => \\\"Where do you travel from?\\\")\" %}\n\n{{- bos_token }}\n\n{%- if messages[0]['role'] == 'system' %}\n    {%- set system_message = messages[0]['content'] %}\n    {%- set loop_messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = default_system_message %}\n    {%- set loop_messages = messages %}\n{%- endif %}\n{{- '[SYSTEM_PROMPT]' + system_message + '[/SYSTEM_PROMPT]' }}\n\n{%- for message in loop_messages %}\n    {%- if message['role'] == 'user' %}\n        {{- '[INST]' + message['content'] + '[/INST]' }}\n    {%- elif message['role'] == 'system' %}\n        {{- '[SYSTEM_PROMPT]' + message['content'] + '[/SYSTEM_PROMPT]' }}\n    {%- elif message['role'] == 'assistant' %}\n        {{- message['content'] + eos_token }}\n    {%- else %}\n        {{- raise_exception('Only user, system and assistant roles are supported!') }}\n    {%- endif %}\n{%- endfor %}",
      "eos_token": "</s>",
      "stop": [
        "</s>"
      ]
    },
    "context_length": 32768,
    "created": 1743449087,
    "display_name": "Arcee AI Blitz",
    "id": "arcee-ai/arcee-blitz",
    "license": "apache-2.0",
    "link": "https://huggingface.co/api/models/togethercomputer/Arcee-Blitz",
    "object": "model",
    "organization": "Arcee AI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.45,
      "output": 0.75
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<｜begin▁of▁sentence｜>",
      "chat_template": "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set system_prompt='' %}{% set is_tool = false %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set is_tool = false -%}{%- set is_output_first = true -%}{%- set is_first = false -%}{%- for tool in message['tool_calls']%}{%- if is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set is_first = true -%}{%- else %}{{'\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set parts = content | split('</think>') %}{% set content = parts[parts.length-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set is_tool = true -%}{%- if is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set is_output_first = false %}{%- else %}{{'\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not is_tool %}{{'<｜Assistant｜>'}}{% endif %}",
      "eos_token": "<｜end▁of▁sentence｜>",
      "max_output_length": 32768,
      "stop": [
        "<｜end▁of▁sentence｜>"
      ]
    },
    "context_length": 163840,
    "created": 1750184204,
    "display_name": "DeepSeek R1 0528 Throughput",
    "id": "deepseek-ai/DeepSeek-R1-0528-tput",
    "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1",
    "object": "model",
    "organization": "DeepSeek",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.55,
      "output": 2.19
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|endoftext|>",
      "chat_template": "{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- messages[0]['content'] }}\n    {%- else %}\n        {{- 'You are Virtuoso Medium, created by Arcee AI. You are a helpful assistant.' }}\n    {%- endif %}\n    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n    {%- else %}\n        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {{- '<|im_start|>' + message.role }}\n        {%- if message.content %}\n            {{- '\\n' + message.content }}\n        {%- endif %}\n        {%- for tool_call in message.tool_calls %}\n            {%- if tool_call.function is defined %}\n                {%- set tool_call = tool_call.function %}\n            {%- endif %}\n            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n            {{- tool_call.name }}\n            {{- '\", \"arguments\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- '}\\n</tool_call>' }}\n        {%- endfor %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n' }}\n{%- endif %}\n",
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>"
      ]
    },
    "context_length": 131072,
    "created": 1743430178,
    "display_name": "Arcee AI Virtuoso-Medium",
    "id": "arcee-ai/virtuoso-medium-v2",
    "license": "apache-2.0",
    "link": "https://huggingface.co/api/models/togethercomputer/Virtuoso-Medium-v2",
    "object": "model",
    "organization": "Arcee AI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.5,
      "output": 0.8
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|endoftext|>",
      "chat_template": null,
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>"
      ]
    },
    "context_length": 32768,
    "created": 1743531347,
    "display_name": "Arcee AI Caller",
    "id": "arcee-ai/caller",
    "link": "https://huggingface.co/api/models/togethercomputer/arcee-ai-caller",
    "object": "model",
    "organization": "Arcee AI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.55,
      "output": 0.85
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": null,
      "eos_token": "<|eot_id|>",
      "stop": [
        "<|eot_id|>"
      ]
    },
    "context_length": 4096,
    "created": 1747581847,
    "display_name": "Marin 8B Instruct",
    "id": "marin-community/marin-8b-instruct",
    "license": "apache-2.0",
    "link": "https://huggingface.co/api/models/marin-community/marin-8b-instruct",
    "object": "model",
    "organization": "Marin Community",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.18000000000000002,
      "output": 0.18000000000000002
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "[BOS]",
      "chat_template": null,
      "eos_token": "[|endofturn|]",
      "stop": [
        "[|endofturn|]",
        "[EOS]"
      ]
    },
    "context_length": 32768,
    "created": 1748542032,
    "display_name": "EXAONE Deep 32B",
    "id": "lgai/exaone-deep-32b",
    "license": "exaone",
    "link": "https://huggingface.co/LGAI-EXAONE/EXAONE-Deep-32B",
    "object": "model",
    "organization": "LG AI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "context_length": 65536,
    "created": 1743212460,
    "display_name": "Gemma 3 27b it",
    "id": "google/gemma-3-27b-it",
    "object": "model",
    "organization": "Google",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<｜begin▁of▁sentence｜>",
      "chat_template": "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set system_prompt='' %}{% set is_tool = false %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set is_tool = false -%}{%- set is_output_first = true -%}{%- set is_first = false -%}{%- for tool in message['tool_calls']%}{%- if is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set is_first = true -%}{%- else %}{{'\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set parts = content | split('</think>') %}{% set content = parts[parts.length-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set is_tool = true -%}{%- if is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set is_output_first = false %}{%- else %}{{'\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not is_tool %}{{'<｜Assistant｜>'}}{% endif %}",
      "eos_token": "<｜end▁of▁sentence｜>",
      "max_output_length": 32768,
      "stop": [
        "<｜end▁of▁sentence｜>"
      ]
    },
    "context_length": 131072,
    "created": 1738048961,
    "display_name": "DeepSeek R1 Distill Llama 70B",
    "id": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "license": "mit",
    "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "object": "model",
    "organization": "DeepSeek",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 2,
      "output": 2
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<s>",
      "chat_template": "{{bos_token}}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}",
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>"
      ]
    },
    "context_length": 32768,
    "created": 1705292440,
    "display_name": "Nous Hermes 2 Mixtral 8X7B Dpo",
    "id": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    "license": "apache-2.0",
    "link": "https://huggingface.co/api/models/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    "object": "model",
    "organization": "Nousresearch",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.6,
      "output": 0.6
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<s>",
      "chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\\n' + system_message + '\\n<</SYS>>\\n\\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' or message['role'] == 'tool' %}{{ bos_token + '[INST] ' + content + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>\\n' + content + '\\n<</SYS>>\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content + ' ' + eos_token }}{% endif %}{% endfor %}",
      "eos_token": "</s>",
      "stop": [
        "</s>"
      ]
    },
    "context_length": 32768,
    "created": 1695860851,
    "display_name": "Mistral (7B) Instruct",
    "id": "mistralai/Mistral-7B-Instruct-v0.1",
    "license": "apache-2.0",
    "link": "https://huggingface.co/api/models/mistralai/Mistral-7B-Instruct-v0.1",
    "object": "model",
    "organization": "mistralai",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.2,
      "output": 0.2
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{{- bos_token }}\n{%- if custom_tools is defined and custom_tools%}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if tools is defined and tools %}\n    {%- set tool_definition = tool_definition ~ (tools | tojson(indent=4)) %}\n{%- else %}\n    {%- set tools = none %}\n{%- endif %}\n\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0]['role'] == 'system' %}\n    {%- set user_provided_system_message = true %}\n    {%- if messages[0]['content'] is string %}\n        {%- set system_message = messages[0]['content']|trim %}\n    {%- else %}\n        {%- set system_message = messages[0]['content'][0]['text']|trim %}\n    {%- endif %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- if tools is not none  %}\n        {#- Since not system_message was provided by user, if tool is provided, system_message is now default tool system message #}\n        {#- This system message is from llama website:https://www.llama.com/docs/model-cards-and-prompt-formats/llama4/  #}\n        {%- set system_message = \"You are a helpful assistant and an expert in function composition. You can answer general questions using your internal knowledge OR invoke functions when necessary. Follow these strict guidelines:\\n\\n1. FUNCTION CALLS:\\n- ONLY use functions that are EXPLICITLY listed in the function list below\\n- If NO functions are listed (empty function list []), respond ONLY with internal knowledge or \\\"I don't have access to [Unavailable service] information\\\"\\n- If a function is not in the list, respond ONLY with internal knowledge or \\\"I don't have access to [Unavailable service] information\\\"\\n- If ALL required parameters are present AND the query EXACTLY matches a listed function's purpose: output ONLY the function call(s)\\n- Use exact format: [\\n  {\\n    \\\"name\\\": \\\"<tool_name_foo>\\\",\\n    \\\"parameters\\\": {\\n      \\\"<param1_name>\\\": \\\"<param1_value>\\\",\\n      \\\"<param2_name>\\\": \\\"<param2_value>\\\"\\n    }\\n  }\\n]\\nExamples:\\nCORRECT: [\\n  {\\n    \\\"name\\\": \\\"get_weather\\\",\\n    \\\"parameters\\\": {\\n      \\\"location\\\": \\\"Vancouver\\\"\\n    }\\n  },\\n  {\\n    \\\"name\\\": \\\"calculate_route\\\",\\n    \\\"parameters\\\": {\\n      \\\"start\\\": \\\"Boston\\\",\\n      \\\"end\\\": \\\"New York\\\"\\n    }\\n  }\\n] <- Only if get_weather and calculate_route are in function list\\n\\nINCORRECT: [\\n  {\\n    \\\"name\\\": \\\"population_projections\\\",\\n    \\\"parameters\\\": {\\n      \\\"country\\\": \\\"United States\\\",\\n      \\\"years\\\": 20\\n    }\\n  }\\n]}] <- Bad json format\\nINCORRECT: Let me check the weather: [\\n  {\\n    \\\"name\\\": \\\"get_weather\\\",\\n    \\\"parameters\\\": {\\n      \\\"location\\\": \\\"Vancouver\\\"\\n    }\\n  }]\\nINCORRECT: [\\n  {\\n    \\\"name\\\": \\\"get_events\\\",\\n    \\\"parameters\\\": {\\n      \\\"location\\\": \\\"Singapore\\\"\\n    }\\n  }] <- If function not in list\\n\\n2. RESPONSE RULES:\\n- For pure function requests matching a listed function: ONLY output the function call(s)\\n- For knowledge questions: ONLY output text\\n- For missing parameters: ONLY request the specific missing parameters\\n- For unavailable services (not in function list): output ONLY with internal knowledge or \\\"I don't have access to [Unavailable service] information\\\". Do NOT execute a function call.\\n- If the query asks for information beyond what a listed function provides: output ONLY with internal knowledge about your limitations\\n- NEVER combine text and function calls in the same response\\n- NEVER suggest alternative functions when the requested service is unavailable\\n- NEVER create or invent new functions not listed below\\n\\n3. STRICT BOUNDARIES:\\n- ONLY use functions from the list below - no exceptions\\n- NEVER use a function as an alternative to unavailable information\\n- NEVER call functions not present in the function list\\n- NEVER add explanatory text to function calls\\n- NEVER respond with empty brackets\\n- Use proper Python/JSON syntax for function calls\\n- Check the function list carefully before responding\\n\\n4. TOOL RESPONSE HANDLING:\\n- When receiving tool responses: provide concise, natural language responses\\n- Don't repeat tool response verbatim\\n- Don't add supplementary information\\n\\nHere is a list of functions in JSON format that you can invoke:\\n\" %}\n    {%- else %}\n        {%- set system_message = \"\" %}\n    {%- endif %}\n{%- endif %}\n{#- Now writing the system message: use the user provided system message if user_provided_system_message, else default tool system message if tools presented #}\n{%- if system_message %}\n    {#- always use user provided system message to override default tool system message #}\n    {{- \"<|header_start|>system<|header_end|>\\n\\n\" }}\n    {{- system_message }}\n    {%- if user_provided_system_message and tools %}\n        {{- \"\\nHere is a list of functions in JSON format that you can invoke. Use exact format: [func_name1(param1=value1, param2=value2), func_name2(...)]\\n\" }}\n        {{- tool_definition -}}\n        {%- elif tool_definition %}\n        {{- tool_definition -}}\n    {%- endif %}\n    {{- \"<|eot|>\" }}\n{%- endif %}\n\n{#- Now deal with all other messages #}\n{%- for message in messages %}\n    {#- Base case: messages that are not from tool role and has empty tool_call list  #}\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or ('tool_calls' in message and  message.tool_calls|length != 0 )) %}\n        {{- '<|header_start|>' + message['role'] + '<|header_end|>\\n\\n' }}\n        {%- if message['content'] is string %}\n            {{- message['content'] }}\n        {%- else %}\n            {%- for content in message['content'] %}\n                {%- if content['type'] == 'image' %}\n                    {{- '<|image|>' }}\n                {%- elif content['type'] == 'text' %}\n                    {{- content['text'] | trim }}\n                {%- endif %}\n            {%- endfor %}\n        {%- endif %}\n    {{- \"<|eot|>\" }}\n    {#- Tool case: messages has non-empty tool_call list, must from assistant #}\n    {%- elif 'tool_calls' in message %}\n        {#- assume tool_calls are always coming from assistant #}\n        {%- if message.role == 'assistant' %}\n            {{- '<|header_start|>assistant<|header_end|>\\n\\n' -}}\n        {%- if message['content'] is string %}\n            {{- message['content'] }}\n        {%- else %}\n            {%- for content in message['content'] %}\n                {%- if content['type'] == 'image' %}\n                    {{- '<|image|>' }}\n                {%- elif content['type'] == 'text' %}\n                    {{- content['text'] }}\n                {%- endif %}\n            {%- endfor %}\n        {%- endif %}\n            {{- \"[\" }}\n        {%- for tool_call in message.tool_calls %}\n            {%- if tool_call.function is defined %}\n                {%- set tool_call = tool_call.function %}\n            {%- endif %}\n                {{-  tool_call.name + '(' -}}\n            {%- for param, needed in tool_call.arguments %}\n                {{- param + '=\"' -}}\n                {{- \"%s\" | format(tool_call.arguments[param]) -}}\n                {{- '\"' -}}\n                {% if not loop.last %}, {% endif %}\n            {%- endfor %}\n            {{- ')' -}}\n            {% if not loop.last %}, {% endif %}\n        {%- endfor %}\n        {{- \"]<|eot|>\" }}\n{%- endif %}\n{#- Tool_response case: messages are from tool_response  #}\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n        {{- \"<|header_start|>ipython<|header_end|>\\n\\n\" }}\n        {%- if message.content is string %}\n            {{-  message.content  | tojson }}\n        {%- else %}\n            {%- for content in message['content']  %}\n                {%- if content['type']  == 'text' %}\n                    {{-  content['text'] | tojson }}\n                {%- endif %}\n            {%- endfor %}\n        {%- endif %}\n        {{- \"<|eot|>\" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|header_start|>assistant<|header_end|>\\n\\n' }}\n{%- endif %}",
      "eos_token": "<|eot|>",
      "max_output_length": 32768,
      "stop": [
        "<|eot|>",
        "<|eom|>"
      ]
    },
    "context_length": 1048576,
    "created": 1743878353,
    "display_name": "Llama 4 Maverick Instruct (17Bx128E)",
    "id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
    "license": "llama4",
    "link": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.27,
      "output": 0.85
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<｜begin▁of▁sentence｜>",
      "chat_template": "{% if not add_generation_prompt %}{% set add_generation_prompt = false %}{% endif %}{# Initialize variables since Nunjucks doesn't support namespace #}{% set is_first = false %}{% set is_tool = false %}{% set is_output_first = true %}{% set system_prompt = '' %}{# Get system prompt #}{% for message in messages %}{% if message.role == 'system' %}{% set system_prompt = message.content %}{% endif %}{% endfor %}{{bos_token}}{{system_prompt}}{% for message in messages %}{% if message.role == 'user' %}{% set is_tool = false %}<｜User｜>{{message.content}}{% endif %}{% if message.role == 'assistant' and not message.content %}{% set is_tool = false %}{% for tool in message.tool_calls %}{% if not is_first %}<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>{{tool.type}}<｜tool▁sep｜>{{tool.function.name}}```json{{tool.function.arguments}}```<｜tool▁call▁end｜>{% set is_first = true %}{% else %}<｜tool▁call▁begin｜>{{tool.type}}<｜tool▁sep｜>{{tool.function.name}}```json{{tool.function.arguments}}```<｜tool▁call▁end｜><｜tool▁calls▁end｜><｜end▁of▁sentence｜>{% endif %}{% endfor %}{% endif %}{% if message.role == 'assistant' and message.content %}{% if is_tool %}<｜tool▁outputs▁end｜>{{message.content}}<｜end▁of▁sentence｜>{% set is_tool = false %}{% else %}{% set content = message.content %}{% if '</think>' in content %}{% set parts = content | split('</think>') %}{% set content = parts[parts.length-1] %}{% endif %}<｜Assistant｜>{{content}}<｜end▁of▁sentence｜>{% endif %}{% endif %}{% if message.role == 'tool' %}{% set is_tool = true %}{% if is_output_first %}<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>{{message.content}}<｜tool▁output▁end｜>{% set is_output_first = false %}{% else %}<｜tool▁output▁begin｜>{{message.content}}<｜tool▁output▁end｜>{% endif %}{% endif %}{% endfor %}{% if is_tool %}<｜tool▁outputs▁end｜>{% endif %}{% if add_generation_prompt and not is_tool %}<｜Assistant｜>{% endif %}",
      "eos_token": "<｜end▁of▁sentence｜>",
      "max_output_length": 32768,
      "stop": [
        "<｜end▁of▁sentence｜>"
      ]
    },
    "context_length": 131072,
    "created": 1738182549,
    "display_name": "DeepSeek R1 Distill Qwen 14B",
    "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
    "license": "mit",
    "link": "https://huggingface.co/api/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
    "object": "model",
    "organization": "DeepSeek",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 1.6,
      "output": 1.6
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<｜begin▁of▁sentence｜>",
      "chat_template": "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set system_prompt='' %}{% set is_tool = false %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set is_tool = false -%}{%- set is_output_first = true -%}{%- set is_first = false -%}{%- for tool in message['tool_calls']%}{%- if is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set is_first = true -%}{%- else %}{{'\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set parts = content | split('</think>') %}{% set content = parts[parts.length-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set is_tool = true -%}{%- if is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set is_output_first = false %}{%- else %}{{'\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not is_tool %}{{'<｜Assistant｜>'}}{% endif %}",
      "eos_token": "<｜end▁of▁sentence｜>",
      "stop": [
        "<｜end▁of▁sentence｜>"
      ]
    },
    "context_length": 8192,
    "created": 1738187359,
    "display_name": "DeepSeek R1 Distill Llama 70B Free",
    "id": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free",
    "license": "mit",
    "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "object": "model",
    "organization": "DeepSeek",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<bos>",
      "chat_template": "{#- Begin-of-sequence token to start the model prompt -#}\n{{ bos_token }}\n{#- Extracts the system message. Gemma does not support system messages so it will be prepended to first user message. -#}\n{%- if messages[0]['role'] == 'system' -%}\n    {%- if messages[0]['content'] is string -%}\n        {%- set first_user_prefix = messages[0]['content'] -%}\n    {%- else -%}\n        {%- set first_user_prefix = messages[0]['content'][0]['text'] -%}\n    {%- endif -%}\n    {%- set loop_messages = messages[1:] -%}\n{%- else -%}\n    {%- set first_user_prefix = \"You are a helpful assistant named Typhoon created by SCB 10X to be helpful, harmless, and honest.\" -%}\n    {%- set loop_messages = messages -%}\n{%- endif -%}\n{%- if enable_thinking is defined and enable_thinking is true %}\n    {%- set first_user_prefix = first_user_prefix + \" First, think through the reasoning internally, then present the reasoning within <think>...</think>. After thinking, clearly state a response that addresses the user's request and aligns with their preferences, not just providing a direct answer.\" -%}\n{%- endif %}\n{%- set first_user_prefix = first_user_prefix + '\\n\\n' -%}\n{#- Set tools to none if not defined for this ChatCompletion request (helps avoid errors later) -#}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- If given only system message -#}\n{%- if loop_messages|length == 0 -%}\n    {{ '<start_of_turn>user\\n' -}}\n    {{ first_user_prefix }}\n    {#- Append system message with tool information if using tools in message request. -#}\n    {%- if tools is not none -%}\n        {{- \"Tools (functions) are available. If you decide to invoke one or more of the tools, you must respond with a python list of the function calls.\\n\" -}}\n        {{- \"Example Format: [func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)] \\n\" -}}\n        {{- \"Do not use variables. DO NOT USE MARKDOWN SYNTAX. You SHOULD NOT include any other text in the response if you call a function. If none of the functions can be used, point it out. If you lack the parameters required by the function, also point it out.\\n\" -}}\n        {{- \"Here is a list of functions in JSON format that you can invoke.\\n\" -}}\n        {{- tools | tojson(indent=4) -}}\n        {{- \"\\n\\n\" -}}\n    {%- endif -%}\n{%- endif %}\n\n{#- Main loop over all messages in the conversation history -#}\n{%- for message in loop_messages -%}\n    {#- Normalize roles for model prompt formatting -#}\n    {%- if (message['role'] == 'assistant') -%}\n        {%- set role = \"model\" -%}\n    {%- elif (message['role'] == 'tool') -%}\n        {%- set role = \"user\" -%}\n    {%- else -%}\n        {%- set role = message['role'] -%}\n    {%- endif -%}\n    {#- Mark the start of a message block with the appropriate role -#}\n    {{ '<start_of_turn>' + role + '\\n' -}}\n\n    {#- Insert system message content (if present) at the beginning of the first message. -#}\n    {%- if loop.first -%}\n        {{ first_user_prefix }}\n        {#- Append system message with tool information if using tools in message request. -#}\n        {%- if tools is not none -%}\n            {{- \"Tools (functions) are available. If you decide to invoke one or more of the tools, you must respond with a python list of the function calls.\\n\" -}}\n            {{- \"Example Format: [func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)] \\n\" -}}\n            {{- \"Do not use variables. DO NOT USE MARKDOWN SYNTAX. You SHOULD NOT include any other text in the response if you call a function. If none of the functions can be used, point it out. If you lack the parameters required by the function, also point it out.\\n\" -}}\n            {{- \"Here is a list of functions in JSON format that you can invoke.\\n\" -}}\n            {{- tools | tojson(indent=4) -}}\n            {{- \"\\n\\n\" -}}\n        {%- endif -%}\n    {%- endif -%}\n\n    {#- Format model tool calls (turns where model indicates they want to call a tool) -#}\n    {%- if 'tool_calls' in message -%}\n        {#- Opening bracket for tool call list. -#}\n        {{- '[' -}}\n        {#- For each tool call -#}\n        {%- for tool_call in message.tool_calls -%}\n            {#- Function name & opening parenthesis. -#}\n            {%- if tool_call.function is defined -%}\n                {%- set tool_call = tool_call.function -%}\n            {%- endif -%}\n            {{- tool_call.name + '(' -}}\n\n            {#-- Handle arguments as list (positional) or dict (named) --#}\n            {#-- Named arguments (dict) --#}\n            {%- if tool_call.arguments is iterable and tool_call.arguments is mapping -%}\n                {%- set first = true -%}\n                {%- for key, val in tool_call.arguments.items() -%}\n                    {%- if not first %}, {% endif -%}\n                    {{ key }}={{ val | tojson }}\n                    {%- set first = false -%}\n                {%- endfor -%}\n            {#-- Positional arguments (list) --#}\n            {%- elif tool_call.arguments is iterable -%}\n                {{- tool_call.arguments | map('tojson') | join(', ') -}}\n            {#-- Fallback: single positional value --#}\n            {%- else -%}\n                {{- tool_call.arguments | tojson -}}\n            {#-- Closing parenthesis. --#}\n            {%- endif -%}\n                {{- ')' -}}\n            {#-- If more than one tool call, place comma and move to formatting next tool call --#}\n            {%- if not loop.last -%}, {% endif -%}\n        {%- endfor -%}\n        {#- Closing bracket for tool call list. -#}\n        {{- ']' -}}\n    {%- endif -%}\n    \n    {#- Tool response start tag (for messages from a tool) -#}\n    {%- if (message['role'] == 'tool') -%}\n        {{ '<tool_response>\\n' -}}\n    {%- endif -%}\n\n    {#- Render the message content: handle plain string or multimodal content like image/text -#}\n    {%- if message['content'] is string -%}\n        {%- set content = message['content'] -%}\n        {%- if '</think>' in content -%}\n            {%- set content = content.split('</think>')[-1] -%}\n        {%- endif -%}\n        {{ content | trim }}\n    {%- elif message['content'] is iterable -%}\n        {%- for item in message['content'] -%}\n            {%- if item['type'] == 'image' -%}\n                {{ '<start_of_image>' }}\n            {%- elif item['type'] == 'text' -%}\n                {%- set content = item['text'] -%}\n                {%- if '</think>' in content -%}\n                    {%- set content = content.split('</think>')[-1] -%}\n                {%- endif -%}\n                {{ content | trim }}\n            {%- endif -%}\n        {%- endfor -%}\n    {%- else -%}\n        {{ raise_exception(\"Invalid content type\") }}\n    {%- endif -%}\n\n    {#- Tool response end tag -#}\n    {%- if (message['role'] == 'tool') -%}\n        {{ '</tool_response>' -}}\n    {%- endif -%}\n\n    {#- Mark end of a single turn -#}\n    {{ '<end_of_turn>\\n' }}\n{%- endfor -%}\n\n{#- If generation is to be triggered, add model prompt prefix -#}\n{%- if add_generation_prompt -%}\n    {{'<start_of_turn>model\\n'}}\n    {%- if enable_thinking is defined and enable_thinking is true -%}\n        {{- '<think>' -}}\n    {%- endif %}\n{%- endif -%}",
      "eos_token": "<end_of_turn>",
      "stop": [
        "<end_of_turn>"
      ]
    },
    "context_length": 131072,
    "created": 1749574497,
    "display_name": "Typhoon 2.1 12B",
    "id": "scb10x/scb10x-typhoon-2-1-gemma3-12b",
    "license": "gemma",
    "link": "https://huggingface.co/api/models/togethercomputer/typhoon2.1-gemma3-12b",
    "object": "model",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.2,
      "output": 0.2
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{%- if messages | length % 2 == 0 -%}\n    {%- set role = 'Agent' -%}\n{%- else -%}\n    {%- set role = 'User' -%}\n{%- endif -%}\n\n{%- if categories is not defined -%}\n    {%- set ns = namespace(contains_image=false) -%}\n\n    {%- for message in messages -%}\n        {%- for content in message['content'] | selectattr('type', 'equalto', 'image') -%}\n            {%- set ns.contains_image = true -%}\n        {%- endfor -%}\n    {%- endfor -%}\n\n    {%- if ns.contains_image -%}\n        {%- set categories = {\n            \"S1\": \"Violent Crimes.\",\n            \"S2\": \"Non-Violent Crimes.\",\n            \"S3\": \"Sex Crimes.\",\n            \"S4\": \"Child Exploitation.\",\n            \"S5\": \"Defamation.\",\n            \"S6\": \"Specialized Advice.\",\n            \"S7\": \"Privacy.\",\n            \"S8\": \"Intellectual Property.\",\n            \"S9\": \"Indiscriminate Weapons.\",\n            \"S10\": \"Hate.\",\n            \"S11\": \"Self-Harm.\",\n            \"S12\": \"Sexual Content.\",\n            \"S13\": \"Elections.\",\n        } -%}\n    {%- else -%}\n        {%- set categories = {\n            \"S1\": \"Violent Crimes.\",\n            \"S2\": \"Non-Violent Crimes.\",\n            \"S3\": \"Sex Crimes.\",\n            \"S4\": \"Child Exploitation.\",\n            \"S5\": \"Defamation.\",\n            \"S6\": \"Specialized Advice.\",\n            \"S7\": \"Privacy.\",\n            \"S8\": \"Intellectual Property.\",\n            \"S9\": \"Indiscriminate Weapons.\",\n            \"S10\": \"Hate.\",\n            \"S11\": \"Self-Harm.\",\n            \"S12\": \"Sexual Content.\",\n            \"S13\": \"Elections.\",\n            \"S14\": \"Code Interpreter Abuse.\",\n        } -%}\n    {%- endif -%}\n{%- endif -%}\n\n{{ \"<|begin_of_text|><|header_start|>user<|header_end|>\\n\" }}\n{{ \"Task: Check if there is unsafe content in '\" + role + \"' messages in conversations according to our safety policy with the below categories.\\n\" }}\n{{ \"<BEGIN UNSAFE CONTENT CATEGORIES>\\n\" }}\n\n{%- for key in categories -%}\n    {%- if key not in excluded_category_keys -%}\n        {{ key + \": \" + categories[key] + \"\\n\" }}\n    {%- endif -%}\n{%- endfor -%}\n\n{{ \"<END UNSAFE CONTENT CATEGORIES>\\n\" }}\n{{ \"<BEGIN CONVERSATION>\\n\" }}\n\n{%- for message in messages -%}\n    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) -%}\n        {{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}\n    {%- endif -%}\n\n    {%- set content = message['content'] -%}\n\n    {%- if message['role'] == 'user' -%}\n        {%- set role = 'User' -%}\n    {%- elif message['role'] == 'assistant' -%}\n        {%- set role = 'Agent' -%}\n    {%- endif -%}\n\n    {#— #1 Accumulate all images for this message —#}\n    {%- set ns = namespace(img_tokens='') -%}\n    {%- for img in message.content | selectattr('type', 'equalto', 'image') -%}\n        {%- set ns.img_tokens = ns.img_tokens + '<|image|>' -%}\n    {%- endfor -%}\n\n    {#— #2 Then emit all text —#}\n    {%- for txt in message.content | selectattr('type','equalto','text') -%}\n        {{ role + ': ' }}{{ ns.img_tokens }}{{ txt.text | trim }}\\n\\n\n\n        {#— clear the buffer so only first text prints images —#}\n        {%- if loop.first -%}\n            {%- set ns.img_tokens = '' -%}\n        {%- endif -%}\n    {%- endfor -%}\n{%- endfor -%}\n\n{{ \"<END CONVERSATION>\\n\" }}\n{{ \"Provide your safety assessment for ONLY THE LAST \" + role + \" message in the above conversation:\" }}\n{{ \" - First line must read 'safe' or 'unsafe'.\" }}\n{{ \" - If unsafe, a second line must include a comma-separated list of violated categories. <|eot|><|header_start|>assistant<|header_end|>\" }}",
      "eos_token": "<|eot|>",
      "stop": [
        "<|eot|>"
      ]
    },
    "context_length": 1048576,
    "created": 1746038486,
    "display_name": "Llama Guard 4 12B",
    "id": "meta-llama/Llama-Guard-4-12B",
    "license": "other llama4",
    "link": "https://huggingface.co/meta-llama/Llama-Guard-4-12B",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.2,
      "output": 0.2
    },
    "running": false,
    "type": "moderation"
  },
  {
    "config": {
      "bos_token": "<s>",
      "chat_template": null,
      "eos_token": "</s>",
      "stop": [
        "</s>"
      ]
    },
    "context_length": 16384,
    "created": 1747260038,
    "display_name": "Refuel LLM V2",
    "id": "togethercomputer/Refuel-Llm-V2",
    "license": "cc-by-nc-4.0",
    "link": "https://huggingface.co/api/models/togethercomputer/refuel-llm-v2",
    "object": "model",
    "organization": "Refuel AI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.6,
      "output": 0.6
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|endoftext|>",
      "chat_template": "{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- messages[0]['content'] }}\n    {%- else %}\n        {{- 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.' }}\n    {%- endif %}\n    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n    {%- else %}\n        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {{- '<|im_start|>' + message.role }}\n        {%- if message.content %}\n            {{- '\\n' + message.content }}\n        {%- endif %}\n        {%- for tool_call in message.tool_calls %}\n            {%- if tool_call.function is defined %}\n                {%- set tool_call = tool_call.function %}\n            {%- endif %}\n            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n            {{- tool_call.name }}\n            {{- '\", \"arguments\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- '}\\n</tool_call>' }}\n        {%- endfor %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n' }}\n{%- endif %}\n",
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>"
      ]
    },
    "context_length": 131072,
    "created": 1728633510,
    "display_name": "Qwen2.5 72B Instruct Turbo",
    "id": "Qwen/Qwen2.5-72B-Instruct-Turbo",
    "license": "Qwen",
    "link": "https://huggingface.co/Qwen/Qwen2.5-72B-Instruct",
    "object": "model",
    "organization": "Qwen",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 1.2,
      "output": 1.2
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": "{% if messages.length % 2 == 0 %}{% set final_role = 'Agent' %}{% else %}{% set final_role = 'User' %}{% endif %}[INST] Task: Check if there is unsafe content in '{{ final_role }}' messages in conversations according our safety policy with the below categories.\n\n<BEGIN UNSAFE CONTENT CATEGORIES>\nS1: Violent Crimes.\nS2: Non-Violent Crimes.\nS3: Sex Crimes.\nS4: Child Exploitation.\nS5: Specialized Advice.\nS6: Privacy.\nS7: Intellectual Property.\nS8: Indiscriminate Weapons.\nS9: Hate.\nS10: Self-Harm.\nS11: Sexual Content.\n<END UNSAFE CONTENT CATEGORIES>\n\n<BEGIN CONVERSATION>\n\n{% for message in messages %}{% if message['role'] == 'user' and loop.index0 % 2 == 0 %}User: {{ message['content'].trim() }}{% elif message['role'] == 'assistant' and loop.index0 % 2 != 0 %}Agent: {{ message['content'].trim() }}{% else %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.last %}{% set role = message['role'] %}{% endif %}{{ '\n\n' }}{% endfor %}<END CONVERSATION>\n\nProvide your safety assessment for ONLY THE LAST {{ role }} message in the above conversation:\n - First line must read 'safe' or 'unsafe'.\n - If unsafe, a second line must include a comma-separated list of violated categories. [/INST]",
      "eos_token": null,
      "stop": []
    },
    "context_length": 8192,
    "created": 1713429380,
    "display_name": "Meta Llama Guard 2 8B",
    "id": "meta-llama/LlamaGuard-2-8b",
    "license": "Llama-3 (Other)",
    "link": null,
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.2,
      "output": 0.2
    },
    "running": false,
    "type": "moderation"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{% endif %}",
      "eos_token": "<|end_of_text|>",
      "max_output_length": 8192,
      "stop": [
        "<|eot_id|>"
      ]
    },
    "context_length": 8192,
    "created": 0,
    "display_name": "Meta Llama 3 8B Instruct Lite",
    "id": "meta-llama/Meta-Llama-3-8B-Instruct-Lite",
    "license": "Llama-3 (Other)",
    "link": "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.1,
      "output": 0.1
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<s>",
      "chat_template": null,
      "eos_token": "</s>",
      "stop": [
        "</s>"
      ]
    },
    "context_length": 514,
    "created": 1745513588,
    "display_name": "Multilingual E5 Large Instruct",
    "id": "intfloat/multilingual-e5-large-instruct",
    "license": "mit",
    "link": "https://huggingface.co/api/models/intfloat/multilingual-e5-large-instruct",
    "object": "model",
    "organization": "Intfloat",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.02,
      "output": 0.02
    },
    "running": false,
    "type": "embedding"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{{- bos_token }}\n{%- if custom_tools is defined and custom_tools%}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if tools is defined and tools %}\n    {%- set tool_definition = tool_definition ~ (tools | tojson(indent=4)) %}\n{%- else %}\n    {%- set tools = none %}\n{%- endif %}\n\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0]['role'] == 'system' %}\n    {%- set user_provided_system_message = true %}\n    {%- if messages[0]['content'] is string %}\n        {%- set system_message = messages[0]['content']|trim %}\n    {%- else %}\n        {%- set system_message = messages[0]['content'][0]['text']|trim %}\n    {%- endif %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- if tools is not none  %}\n        {#- Since not system_message was provided by user, if tool is provided, system_message is now default tool system message #}\n        {#- This system message is from llama website:https://www.llama.com/docs/model-cards-and-prompt-formats/llama4/  #}\n        {%- set system_message = \"You are a helpful assistant and an expert in function composition. You can answer general questions using your internal knowledge OR invoke functions when necessary. Follow these strict guidelines:\\n\\n1. FUNCTION CALLS:\\n- ONLY use functions that are EXPLICITLY listed in the function list below\\n- If NO functions are listed (empty function list []), respond ONLY with internal knowledge or \\\"I don't have access to [Unavailable service] information\\\"\\n- If a function is not in the list, respond ONLY with internal knowledge or \\\"I don't have access to [Unavailable service] information\\\"\\n- If ALL required parameters are present AND the query EXACTLY matches a listed function's purpose: output ONLY the function call(s)\\n- Use exact format: [\\n  {\\n    \\\"name\\\": \\\"<tool_name_foo>\\\",\\n    \\\"parameters\\\": {\\n      \\\"<param1_name>\\\": \\\"<param1_value>\\\",\\n      \\\"<param2_name>\\\": \\\"<param2_value>\\\"\\n    }\\n  }\\n]\\nExamples:\\nCORRECT: [\\n  {\\n    \\\"name\\\": \\\"get_weather\\\",\\n    \\\"parameters\\\": {\\n      \\\"location\\\": \\\"Vancouver\\\"\\n    }\\n  },\\n  {\\n    \\\"name\\\": \\\"calculate_route\\\",\\n    \\\"parameters\\\": {\\n      \\\"start\\\": \\\"Boston\\\",\\n      \\\"end\\\": \\\"New York\\\"\\n    }\\n  }\\n] <- Only if get_weather and calculate_route are in function list\\n\\nINCORRECT: [\\n  {\\n    \\\"name\\\": \\\"population_projections\\\",\\n    \\\"parameters\\\": {\\n      \\\"country\\\": \\\"United States\\\",\\n      \\\"years\\\": 20\\n    }\\n  }\\n]}] <- Bad json format\\nINCORRECT: Let me check the weather: [\\n  {\\n    \\\"name\\\": \\\"get_weather\\\",\\n    \\\"parameters\\\": {\\n      \\\"location\\\": \\\"Vancouver\\\"\\n    }\\n  }]\\nINCORRECT: [\\n  {\\n    \\\"name\\\": \\\"get_events\\\",\\n    \\\"parameters\\\": {\\n      \\\"location\\\": \\\"Singapore\\\"\\n    }\\n  }] <- If function not in list\\n\\n2. RESPONSE RULES:\\n- For pure function requests matching a listed function: ONLY output the function call(s)\\n- For knowledge questions: ONLY output text\\n- For missing parameters: ONLY request the specific missing parameters\\n- For unavailable services (not in function list): output ONLY with internal knowledge or \\\"I don't have access to [Unavailable service] information\\\". Do NOT execute a function call.\\n- If the query asks for information beyond what a listed function provides: output ONLY with internal knowledge about your limitations\\n- NEVER combine text and function calls in the same response\\n- NEVER suggest alternative functions when the requested service is unavailable\\n- NEVER create or invent new functions not listed below\\n\\n3. STRICT BOUNDARIES:\\n- ONLY use functions from the list below - no exceptions\\n- NEVER use a function as an alternative to unavailable information\\n- NEVER call functions not present in the function list\\n- NEVER add explanatory text to function calls\\n- NEVER respond with empty brackets\\n- Use proper Python/JSON syntax for function calls\\n- Check the function list carefully before responding\\n\\n4. TOOL RESPONSE HANDLING:\\n- When receiving tool responses: provide concise, natural language responses\\n- Don't repeat tool response verbatim\\n- Don't add supplementary information\\n\\nHere is a list of functions in JSON format that you can invoke:\\n\" %}\n    {%- else %}\n        {%- set system_message = \"\" %}\n    {%- endif %}\n{%- endif %}\n{#- Now writing the system message: use the user provided system message if user_provided_system_message, else default tool system message if tools presented #}\n{%- if system_message %}\n    {#- always use user provided system message to override default tool system message #}\n    {{- \"<|header_start|>system<|header_end|>\\n\\n\" }}\n    {{- system_message }}\n    {%- if user_provided_system_message and tools %}\n        {{- \"\\nHere is a list of functions in JSON format that you can invoke. Use exact format: [func_name1(param1=value1, param2=value2), func_name2(...)]\\n\" }}\n        {{- tool_definition -}}\n        {%- elif tool_definition %}\n        {{- tool_definition -}}\n    {%- endif %}\n    {{- \"<|eot|>\" }}\n{%- endif %}\n\n{#- Now deal with all other messages #}\n{%- for message in messages %}\n    {#- Base case: messages that are not from tool role and has empty tool_call list  #}\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or ('tool_calls' in message and  message.tool_calls|length != 0 )) %}\n        {{- '<|header_start|>' + message['role'] + '<|header_end|>\\n\\n' }}\n        {%- if message['content'] is string %}\n            {{- message['content'] }}\n        {%- else %}\n            {%- for content in message['content'] %}\n                {%- if content['type'] == 'image' %}\n                    {{- '<|image|>' }}\n                {%- elif content['type'] == 'text' %}\n                    {{- content['text'] | trim }}\n                {%- endif %}\n            {%- endfor %}\n        {%- endif %}\n    {{- \"<|eot|>\" }}\n    {#- Tool case: messages has non-empty tool_call list, must from assistant #}\n    {%- elif 'tool_calls' in message %}\n        {#- assume tool_calls are always coming from assistant #}\n        {%- if message.role == 'assistant' %}\n            {{- '<|header_start|>assistant<|header_end|>\\n\\n' -}}\n        {%- if message['content'] is string %}\n            {{- message['content'] }}\n        {%- else %}\n            {%- for content in message['content'] %}\n                {%- if content['type'] == 'image' %}\n                    {{- '<|image|>' }}\n                {%- elif content['type'] == 'text' %}\n                    {{- content['text'] }}\n                {%- endif %}\n            {%- endfor %}\n        {%- endif %}\n            {{- \"[\" }}\n        {%- for tool_call in message.tool_calls %}\n            {%- if tool_call.function is defined %}\n                {%- set tool_call = tool_call.function %}\n            {%- endif %}\n                {{-  tool_call.name + '(' -}}\n            {%- for param, needed in tool_call.arguments %}\n                {{- param + '=\"' -}}\n                {{- \"%s\" | format(tool_call.arguments[param]) -}}\n                {{- '\"' -}}\n                {% if not loop.last %}, {% endif %}\n            {%- endfor %}\n            {{- ')' -}}\n            {% if not loop.last %}, {% endif %}\n        {%- endfor %}\n        {{- \"]<|eot|>\" }}\n{%- endif %}\n{#- Tool_response case: messages are from tool_response  #}\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n        {{- \"<|header_start|>ipython<|header_end|>\\n\\n\" }}\n        {%- if message.content is string %}\n            {{-  message.content  | tojson }}\n        {%- else %}\n            {%- for content in message['content']  %}\n                {%- if content['type']  == 'text' %}\n                    {{-  content['text'] | tojson }}\n                {%- endif %}\n            {%- endfor %}\n        {%- endif %}\n        {{- \"<|eot|>\" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|header_start|>assistant<|header_end|>\\n\\n' }}\n{%- endif %}",
      "eos_token": "<|eot|>",
      "stop": [
        "<|eot|>",
        "<|eom|>"
      ]
    },
    "context_length": 1048576,
    "created": 1743878170,
    "display_name": "Llama 4 Scout Instruct (17Bx16E)",
    "id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "license": "llama4",
    "link": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.18000000000000002,
      "output": 0.5900000000000001
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "context_length": 0,
    "created": 0,
    "display_name": "FLUX.1 Kontext [max]",
    "id": "black-forest-labs/FLUX.1-kontext-max",
    "object": "model",
    "organization": "Black Forest Labs",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "image"
  },
  {
    "config": {
      "bos_token": "[PAD]",
      "chat_template": null,
      "eos_token": "[PAD]",
      "stop": [
        "[PAD]"
      ]
    },
    "context_length": 8192,
    "created": 1747292078,
    "display_name": "Gte Modernbert Base",
    "id": "Alibaba-NLP/gte-modernbert-base",
    "license": "apache-2.0",
    "link": "https://huggingface.co/api/models/Alibaba-NLP/gte-modernbert-base",
    "object": "model",
    "organization": "Alibaba Nlp",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.08,
      "output": 0.08
    },
    "running": false,
    "type": "embedding"
  },
  {
    "config": {
      "bos_token": "<|endoftext|>",
      "chat_template": "{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- messages[0]['content'] }}\n    {%- else %}\n        {{- 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.' }}\n    {%- endif %}\n    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n    {%- else %}\n        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {{- '<|im_start|>' + message.role }}\n        {%- if message.content %}\n            {{- '\\n' + message.content }}\n        {%- endif %}\n        {%- for tool_call in message.tool_calls %}\n            {%- if tool_call.function is defined %}\n                {%- set tool_call = tool_call.function %}\n            {%- endif %}\n            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n            {{- tool_call.name }}\n            {{- '\", \"arguments\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- '}\\n</tool_call>' }}\n        {%- endfor %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n' }}\n{%- endif %}\n",
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>"
      ]
    },
    "context_length": 32768,
    "created": 1747942382,
    "display_name": "Mxbai Rerank Large V2",
    "id": "mixedbread-ai/Mxbai-Rerank-Large-V2",
    "license": "apache-2.0",
    "link": "https://huggingface.co/api/models/mixedbread-ai/mxbai-rerank-large-v2",
    "object": "model",
    "organization": "Mixedbread AI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.1,
      "output": 0.1
    },
    "running": false,
    "type": "rerank"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- if strftime_now is defined %}\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n    {%- else %}\n        {%- set date_string = \"26 Jul 2024\" %}\n    {%- endif %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0]['role'] == 'system' %}\n    {%- set system_message = messages[0]['content']|trim %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = \"\" %}\n{%- endif %}\n\n{#- System message #}\n{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n{%- if tools is not none %}\n    {{- \"Environment: ipython\\n\" }}\n{%- endif %}\n{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- \"<|eot_id|>\" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0]['content']|trim %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n{%- endif %}\n    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n    {{- first_user_message + \"<|eot_id|>\"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n    {%- elif 'tool_calls' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n        {{- '\"parameters\": ' }}\n        {{- tool_call.arguments | tojson }}\n        {{- \"}\" }}\n        {{- \"<|eot_id|>\" }}\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- \"<|eot_id|>\" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n{%- endif %}\n",
      "eos_token": "<|eot_id|>",
      "stop": [
        "<|eot_id|>",
        "<|eom_id|>"
      ]
    },
    "context_length": 131072,
    "created": 1727229064,
    "display_name": "Meta Llama 3.2 3B Instruct Turbo",
    "id": "meta-llama/Llama-3.2-3B-Instruct-Turbo",
    "license": "Llama-3.1 (Other)",
    "link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.060000000000000005,
      "output": 0.060000000000000005
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = \"26 Jul 2024\" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0]['role'] == 'system' %}\n    {%- set system_message = messages[0]['content']|trim %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = \"\" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- \"Environment: ipython\\n\" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n{%- endif %}\n\n{%- if tools is not none and not tools_in_user_message %}\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- \"<|eot_id|>\" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0]['content']|trim %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n{%- endif %}\n    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n    {{- first_user_message + \"<|eot_id|>\"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n    {%- elif 'tool_calls' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + '=\"' + arg_val + '\"' }}\n                {%- if not loop.last %}\n                    {{- \", \" }}\n                {%- endif %}\n                {%- endfor %}\n            {{- \")\" }}\n        {%- else  %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n            {{- '\"parameters\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- \"}\" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we're in ipython mode #}\n            {{- \"<|eom_id|>\" }}\n        {%- else %}\n            {{- \"<|eot_id|>\" }}\n        {%- endif %}\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- \"<|eot_id|>\" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n{%- endif %}\n",
      "eos_token": "<|eot_id|>",
      "stop": [
        "<|eot_id|>",
        "<|eom_id|>"
      ]
    },
    "context_length": 32768,
    "created": 1731110984,
    "display_name": "Llama 3.1 Nemotron 70B Instruct HF",
    "id": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
    "license": "llama3.1",
    "link": "https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
    "object": "model",
    "organization": "nvidia",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.88,
      "output": 0.88
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<｜begin▁of▁sentence｜>",
      "chat_template": "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set is_first = false %}{% set is_tool = false %}{% set is_output_first = true %}{% set system_prompt='' %}{% set is_first_sp = true %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if is_first_sp %}{% set system_prompt = system_prompt + message['content'] %}{% set is_first_sp = false %}{%- else %}{% set system_prompt = system_prompt + '\n\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{% if tools %}{% set system_prompt = system_prompt + '\n\nYou may call one or more functions to assist with the user query.\n\nYou are provided with function signatures within <tools></tools> XML tags:\n<tools>' + (tools | tojson) + '\n</tools>\n\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n<tool_call>\n{\"name\": <function-name>, \"arguments\": <args-json-object>}\n</tool_call>\n' %}{% endif %}{{bos_token}}{{system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set is_first = true -%}{%- else %}{{'\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set is_tool = false -%}{%- else %}{{'<｜Assistant｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set is_tool = true -%}{%- if is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set is_output_first = false %}{%- else %}{{'\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not is_tool %}{{'<｜Assistant｜>'}}{% endif %}",
      "eos_token": "<｜end▁of▁sentence｜>",
      "max_output_length": 12288,
      "stop": [
        "<｜end▁of▁sentence｜>"
      ]
    },
    "context_length": 131072,
    "created": 1735450433,
    "display_name": "DeepSeek V3-0324",
    "id": "deepseek-ai/DeepSeek-V3",
    "link": "https://huggingface.co/deepseek-ai/DeepSeek-V3",
    "object": "model",
    "organization": "DeepSeek",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 1.25,
      "output": 1.25
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "created": 0,
    "display_name": "FLUX.1 [schnell] Free",
    "id": "black-forest-labs/FLUX.1-schnell-Free",
    "link": "https://huggingface.co/black-forest-labs/FLUX.1-schnell",
    "object": "model",
    "organization": "Black Forest Labs",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "image"
  },
  {
    "config": {
      "bos_token": "<|endoftext|>",
      "chat_template": null,
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>"
      ]
    },
    "context_length": 262144,
    "created": 1753233591,
    "display_name": "Qwen3 Coder 480B A35B Instruct Fp8",
    "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    "license": "apache-2.0",
    "link": "https://huggingface.co/api/models/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    "object": "model",
    "organization": "Qwen",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 2,
      "output": 2
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": null,
      "stop": []
    },
    "context_length": 0,
    "created": 0,
    "display_name": "FLUX.1 Kontext [pro]",
    "id": "black-forest-labs/FLUX.1-kontext-pro",
    "object": "model",
    "organization": "Black Forest Labs",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "image"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{{- bos_token }}\n{%- if custom_tools is defined %}\n    {%- set tools = custom_tools %}\n{%- endif %}\n{%- if not tools_in_user_message is defined %}\n    {%- set tools_in_user_message = true %}\n{%- endif %}\n{%- if not date_string is defined %}\n    {%- set date_string = \"26 Jul 2024\" %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n\n{#- This block extracts the system message, so we can slot it into the right place. #}\n{%- if messages[0]['role'] == 'system' %}\n    {%- set system_message = messages[0]['content']|trim %}\n    {%- set messages = messages[1:] %}\n{%- else %}\n    {%- set system_message = \"\" %}\n{%- endif %}\n\n{#- System message + builtin tools #}\n{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n{%- if builtin_tools is defined or tools is not none %}\n    {{- \"Environment: ipython\\n\" }}\n{%- endif %}\n{%- if builtin_tools is defined %}\n    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n{%- endif %}\n{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n{%- if tools is not none and not tools_in_user_message %}\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n{%- endif %}\n{{- system_message }}\n{{- \"<|eot_id|>\" }}\n\n{#- Custom tools are passed in a user message with some extra guidance #}\n{%- if tools_in_user_message and not tools is none %}\n    {#- Extract the first user message so we can plug it in here #}\n    {%- if messages | length != 0 %}\n        {%- set first_user_message = messages[0]['content']|trim %}\n        {%- set messages = messages[1:] %}\n    {%- else %}\n        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n{%- endif %}\n    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n    {{- \"Do not use variables.\\n\\n\" }}\n    {%- for t in tools %}\n        {{- t | tojson(indent=4) }}\n        {{- \"\\n\\n\" }}\n    {%- endfor %}\n    {{- first_user_message + \"<|eot_id|>\"}}\n{%- endif %}\n\n{%- for message in messages %}\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n    {%- elif 'tool_calls' in message %}\n        {%- if not message.tool_calls|length == 1 %}\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n        {%- endif %}\n        {%- set tool_call = message.tool_calls[0].function %}\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\n                {{- arg_name + '=\"' + arg_val + '\"' }}\n                {%- if not loop.last %}\n                    {{- \", \" }}\n                {%- endif %}\n                {%- endfor %}\n            {{- \")\" }}\n        {%- else  %}\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n            {{- '\"parameters\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- \"}\" }}\n        {%- endif %}\n        {%- if builtin_tools is defined %}\n            {#- This means we're in ipython mode #}\n            {{- \"<|eom_id|>\" }}\n        {%- else %}\n            {{- \"<|eot_id|>\" }}\n        {%- endif %}\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n        {%- if message.content is mapping or message.content is iterable %}\n            {{- message.content | tojson }}\n        {%- else %}\n            {{- message.content }}\n        {%- endif %}\n        {{- \"<|eot_id|>\" }}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n{%- endif %}\n",
      "eos_token": "<|eot_id|>",
      "stop": [
        "<|eot_id|>",
        "<|eom_id|>"
      ]
    },
    "context_length": 131072,
    "created": 1721603683,
    "display_name": "Meta Llama 3.1 70B Instruct Turbo",
    "id": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
    "license": "Llama-3.1 (Other)",
    "link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.88,
      "output": 0.88
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": null,
      "chat_template": null,
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>"
      ]
    },
    "context_length": 40960,
    "created": 1752212970,
    "display_name": "Qwen3 32B Fp8",
    "id": "Qwen/Qwen3-32B-FP8",
    "license": "apache-2.0",
    "link": "https://huggingface.co/api/models/Qwen/Qwen3-32B-FP8",
    "object": "model",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0,
      "output": 0
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|begin_of_text|>",
      "chat_template": "{% for message in messages %}\n{% if loop.index0 == 0 %}{{ bos_token }}{% endif %}\n{{ '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n' }}\n{% if message['content'] is string %}\n{{ message['content'] }}\n{% else %}\n{% for content in message['content'] | sort(attribute=\"type\") %}\n{% if content['type'] == 'image' %}\n{{ '<|image|>' }}\n{% elif content['type'] == 'text' %}\n{{ content['text'] }}\n{% endif %}\n{% endfor %}\n{% endif %}\n{{ '<|eot_id|>' }}\n{% endfor %}\n{% if add_generation_prompt %}\n{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n{% endif %}",
      "eos_token": "<|eot_id|>",
      "stop": [
        "<|eot_id|>",
        "<|eom_id|>"
      ]
    },
    "context_length": 131072,
    "created": 1727227657,
    "display_name": "Meta Llama 3.2 90B Vision Instruct Turbo",
    "id": "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo",
    "license": "llama",
    "link": "https://huggingface.co/meta-llama/Llama-3.2-90B-Vision-Instruct",
    "object": "model",
    "organization": "Meta",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 1.2,
      "output": 1.2
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|endoftext|>",
      "chat_template": "{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- messages[0]['content'] }}\n    {%- else %}\n        {{- 'You are Virtuoso Large, created by Arcee AI. You are a helpful assistant.' }}\n    {%- endif %}\n    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0]['role'] == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n    {%- else %}\n        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {{- '<|im_start|>' + message.role }}\n        {%- if message.content %}\n            {{- '\\n' + message.content }}\n        {%- endif %}\n        {%- for tool_call in message.tool_calls %}\n            {%- if tool_call.function is defined %}\n                {%- set tool_call = tool_call.function %}\n            {%- endif %}\n            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n            {{- tool_call.name }}\n            {{- '\", \"arguments\": ' }}\n            {{- tool_call.arguments | tojson }}\n            {{- '}\\n</tool_call>' }}\n        {%- endfor %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n' }}\n{%- endif %}\n",
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>"
      ]
    },
    "context_length": 131072,
    "created": 1745522892,
    "display_name": "Arcee AI Virtuoso-Large",
    "id": "arcee-ai/virtuoso-large",
    "link": "https://huggingface.co/api/models/togethercomputer/arcee-ai-Virtuoso-Large",
    "object": "model",
    "organization": "Arcee AI",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.75,
      "output": 1.2
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<bos>",
      "chat_template": null,
      "eos_token": "<eos>",
      "stop": [
        "<eos>"
      ]
    },
    "context_length": 32768,
    "created": 1750955040,
    "display_name": "Gemma 3N E4B Instruct",
    "id": "google/gemma-3n-E4B-it",
    "license": "gemma",
    "link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "object": "model",
    "organization": "Google",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.02,
      "output": 0.04
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "<|endoftext|>",
      "chat_template": null,
      "eos_token": "<|im_end|>",
      "stop": [
        "<|im_end|>"
      ]
    },
    "context_length": 262144,
    "created": 1753218184,
    "display_name": "Qwen3 235B A22B Instruct 2507 FP8 Throughput",
    "id": "Qwen/Qwen3-235B-A22B-Instruct-2507-tput",
    "license": "apache-2.0",
    "link": "https://huggingface.co/api/models/Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
    "object": "model",
    "organization": "Qwen",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 0.2,
      "output": 0.6
    },
    "running": false,
    "type": "chat"
  },
  {
    "config": {
      "bos_token": "[BOS]",
      "chat_template": null,
      "eos_token": "[EOS]",
      "max_output_length": 32768,
      "stop": [
        "[EOS]"
      ]
    },
    "context_length": 131072,
    "created": 1752305811,
    "display_name": "Kimi K2 Instruct",
    "id": "moonshotai/Kimi-K2-Instruct",
    "license": "other modified-mit",
    "link": "https://huggingface.co/moonshotai/Kimi-K2-Instruct",
    "object": "model",
    "organization": "Moonshotai",
    "pricing": {
      "base": 0,
      "finetune": 0,
      "hourly": 0,
      "input": 1,
      "output": 3
    },
    "running": false,
    "type": "chat"
  }
]