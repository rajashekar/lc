# lc - LLM Client
<p align="center">
<img src="docs-site/static/img/social-card.png" alt="LLM Client" width="450" />
</p>

[![Documentation](https://img.shields.io/badge/docs-lc.viwq.dev-blue)](https://lc.viwq.dev)
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)
[![Rust](https://img.shields.io/badge/rust-1.70%2B-orange)](https://www.rust-lang.org)

A fast, Rust-based command-line tool for interacting with Large Language Models through OpenAI-compatible APIs. This tool is inspired by Simon Willison's [llm](https://github.com/simonw/llm).

## Quick Start

```bash
# Install from source
git clone <repository-url>
cd lc
cargo build --release

# Add a provider
lc providers add openai https://api.openai.com/v1

# Set your API key
lc keys add openai

# Start chatting
lc -m openai:gpt-4 "What is the capital of France?"
or
# set default provider and model
lc config set provider openai
lc config set model gpt-4
# Direct prompt with specific model
lc "What is the capital of France?"
```

## Key Features

- üöÄ **Lightning Fast** - ~3ms cold start (50x faster than Python alternatives)
- üîß **Universal** - Works with any OpenAI-compatible API
- üß† **Smart** - Built-in vector database and RAG support
- üõ†Ô∏è **Tools** - Supports Model Context Protocol (MCP)
- üîê **Secure** - Encrypted configuration sync
- üí¨ **Intuitive** - Simple commands with short aliases

## Documentation

For comprehensive documentation, visit **[lc.viwq.dev](https://lc.viwq.dev)**

### Quick Links

- [Installation Guide](https://lc.viwq.dev/getting-started/installation)
- [Quick Start Tutorial](https://lc.viwq.dev/getting-started/quick-start)
- [Command Reference](https://lc.viwq.dev/commands/overview)
- [Provider Setup](https://lc.viwq.dev/features/providers)
- [Vector Database & RAG](https://lc.viwq.dev/advanced/vector-database)

## Supported Providers

- OpenAI (GPT-4, GPT-3.5)
- Anthropic Claude
- OpenRouter
- Together AI
- GitHub Models
- Vercel v0
- Local models (Ollama)
- Any OpenAI-compatible API

## Example Usage

```bash
# Direct prompt with specific model
lc -m openai:gpt-4 "Explain quantum computing"

# Interactive chat session
lc chat -m anthropic:claude-3.5-sonnet

# Create embeddings
lc embed -m openai:text-embedding-3-small -v knowledge "Important information"

# Search similar content
lc similar -v knowledge "related query"

# RAG-enhanced chat
lc -v knowledge "What do you know about this topic?"
```

## Contributing

Contributions are welcome! Please see our [Contributing Guide](https://lc.viwq.dev/development/contributing).

## License

MIT License - see [LICENSE](LICENSE) file for details.

---

For detailed documentation, examples, and guides, visit **[lc.viwq.dev](https://lc.viwq.dev)**