# Sample configuration file for bedrock.toml
# This is a sanitized version with sensitive values masked
# Replace <your-*> placeholders with your actual values
# Comments below explain what each setting does

# API endpoint URL for this provider
endpoint = "https://bedrock.us-east-1.amazonaws.com"

# API key for authentication - replace with your actual key
api_key = "<your-api-key>"

# List of available models (auto-populated by the tool)
models = []

# API path to fetch available models
models_path = "/foundation-models"

# API path for chat completions
chat_path = "https://bedrock-runtime.us-east-1.amazonaws.com/model/{model}/converse"


[headers]

[vars]

[chat_templates]

[chat_templates.anthropic.claude.*]
request = """
{
  "messages": [
    {% for message in messages %}
    {
      "role": "{{ message.role | system_to_user_role }}",
      "content": [
        {
          "text": "{{ message.content | default(value="") }}"
        }
      ]
    }{% if not loop.last %},{% endif %}
    {% endfor %}
  ],
  "inferenceConfig": {
    {% if max_tokens %}"maxTokens": {{ max_tokens }}{% if temperature %},{% endif %}{% endif %}
    {% if temperature %}"temperature": {{ temperature }}{% endif %}
  }{% if tools %},
  "toolConfig": {
    "tools": {{ tools | json }}
  }{% endif %}
}

"""
response = """
{
  "content": {{ output.message.content[0].text | json }}
}

"""

[chat_templates.]
request = """
{
  "messages": [
    {% for message in messages %}
    {
      "role": "{{ message.role | system_to_user_role }}",
      "content": [
        {
          "text": "{{ message.content | default(value="") }}"
        }
      ]
    }{% if not loop.last %},{% endif %}
    {% endfor %}
  ]{% if max_tokens %},
  "max_tokens": {{ max_tokens }}{% endif %}{% if temperature %},
  "temperature": {{ temperature }}{% endif %}{% if tools %},
  "tools": {{ tools | json }}{% endif %}{% if stream %},
  "stream": {{ stream }}{% endif %}
}

"""
response = """
{
  "content": {{ output.message.content[0].text | json }}
}

"""
