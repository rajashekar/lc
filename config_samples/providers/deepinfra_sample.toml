# Sample configuration file for deepinfra.toml
# This is a sanitized version with sensitive values masked
# Replace <your-*> placeholders with your actual values
# Comments below explain what each setting does

# API endpoint URL for this provider
endpoint = "https://api.deepinfra.com/v1/openai"

# API key for authentication - replace with your actual key
api_key = "<your-api-key>"

# List of available models (auto-populated by the tool)
models = []

# API path to fetch available models
models_path = "/models"

# API path for chat completions
chat_path = "/chat/completions"

# API path for image generation
images_path = "/images/generations"


[headers]

[vars]

[images_templates]

[images_templates.""]
request = """
{
  "prompt": "{{ prompt }}"{% if model %},
  "model": "{{ model }}"{% endif %}{% if n %},
  "n": {{ n }}{% endif %}{% if size %},
  "size": "{{ size }}"{% endif %}{% if quality %},
  "quality": "{{ quality }}"{% endif %}{% if style %},
  "style": "{{ style }}"{% endif %},
  "response_format": "b64_json"
}

"""
response = """
{
  "created": {{ created }},
  "data": [
    {% for item in data %}
    {
      {% if item.b64_json %}"b64_json": "{{ item.b64_json }}"{% endif %}{% if item.url %},
      "url": "{{ item.url }}"{% endif %}
    }{% if not loop.last %},{% endif %}
    {% endfor %}
  ]
}

"""
