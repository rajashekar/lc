# Sample configuration file for config.toml
# This is a sanitized version with sensitive values masked
# Replace <your-*> placeholders with your actual values
# Comments below explain what each setting does

# Default AI provider to use when none is specified
default_provider = "wmt"

# Default model to use with the default provider
default_model = "gpt-4o-mini"

# Maximum number of tokens to generate in responses
max_tokens = 2000

# Controls randomness in responses (0.0 = deterministic, 1.0 = very random)
temperature = 0.699999988079071


[providers]

[aliases]
# Shortcut alias: use '4o-mini' instead of 'openai:gpt-4o-mini'
4o-mini = "openai:gpt-4o-mini"

# Shortcut alias: use 'sonar-pro' instead of 'perplexity:sonar-pro'
sonar-pro = "perplexity:sonar-pro"

# Shortcut alias: use 'w' instead of 'wmt:gpt-4o-mini'
w = "wmt:gpt-4o-mini"

# Shortcut alias: use 'sonar' instead of 'perplexity:sonar'
sonar = "perplexity:sonar"


[templates]
# Prompt template for coding tasks
coding = "You are an expert software engineer who writes clean, efficient code with detailed explanations."

# Prompt template for gitmsg tasks
gitmsg = "Based on below code (git diff), suggest a precise git commit message"

